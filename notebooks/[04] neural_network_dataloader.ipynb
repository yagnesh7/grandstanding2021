{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07f761da",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c22d69a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "\n",
    "from IPython.display import Audio, clear_output, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22f2eeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../scripts/\")\n",
    "\n",
    "import data_loader as dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0abc4197",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning.loggers.csv_logs import CSVLogger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ca68d5",
   "metadata": {},
   "source": [
    "## Arguments & User Defined Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18510fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_path = \"../outputs/all_transcripts.csv\"\n",
    "transcripts = pd.read_csv(transcript_path)\n",
    "\n",
    "# Only for sample purposes:\n",
    "file_path = \"142-orig.wav\"\n",
    "file_transcripts = transcripts.loc[transcripts[\"file\"] == file_path]\n",
    "\n",
    "bert_scores_path = \"../outputs/bert_scores.csv\"\n",
    "bert_scores = pd.read_csv(bert_scores_path)\n",
    "\n",
    "file_transcripts = file_transcripts.merge(bert_scores, on=[\"file\", \"line\"])\n",
    "\n",
    "data_path = \"../outputs/npy/\"\n",
    "\n",
    "batch_size = 32\n",
    "num_workers = 1\n",
    "\n",
    "sequence_len = 2048 #np.max(np.load(\"../outputs/npy/142-orig.wav_shapes.npy\"))\n",
    "write_dir = \"../outputs/splits/\"\n",
    "if not osp.exists(write_dir):\n",
    "    os.makedirs(write_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c744b538",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e97c01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch Dataset\n",
    "# NOTE: REIMPORTED DUE TO EMPTY ERROR IN `../scripts/data_loader.py`\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(\n",
    "        self, metadata, data_dir, y_name=\"gs_score\", trunc_pad_len=2048, in_dim=5\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.metadata = metadata\n",
    "\n",
    "        # Faster than using a .loc on column names directly\n",
    "        self.columns_dict = dict([(c, i) for i, c in enumerate(self.metadata.columns)])\n",
    "        self.data_dir = data_dir\n",
    "        self.y_name = y_name\n",
    "        self.trunc_pad_len = trunc_pad_len\n",
    "        self.in_dim = in_dim\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get row with .iloc\n",
    "        row = self.metadata.iloc[idx]\n",
    "\n",
    "        # Read in pre-computed numpy array\n",
    "        file_name = row[self.columns_dict[\"file\"]]\n",
    "        line_name = row[self.columns_dict[\"line\"]]\n",
    "        npy_path = osp.join(self.data_dir, f\"{file_name}_{line_name}.npy\")\n",
    "        data = np.load(npy_path)\n",
    "\n",
    "        # Get y_true\n",
    "        score = row[self.columns_dict[self.y_name]]\n",
    "\n",
    "        # Pad/Truncate\n",
    "        data_aug = np.zeros((self.trunc_pad_len, self.in_dim))\n",
    "        data_aug[: min(data.shape[0], self.trunc_pad_len), :] = data[\n",
    "            : self.trunc_pad_len\n",
    "        ]\n",
    "        item = {\n",
    "            \"x\": torch.tensor(data_aug, dtype=torch.float),\n",
    "            \"y\": torch.tensor([score], dtype=torch.float),\n",
    "        }\n",
    "\n",
    "        return (item['x'],item['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c83e956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0000, 0.0000, 0.0407, 0.0000, 0.0000],\n",
       "         [8.2564, 1.0000, 0.1086, 0.0000, 0.0000],\n",
       "         [8.2897, 1.0000, 0.0780, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]),\n",
       " tensor([-0.5621]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset = AudioDataset(file_transcripts, data_path)\n",
    "next(iter(new_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1de0a2",
   "metadata": {},
   "source": [
    "## Data Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5d20553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch Lightning Module\n",
    "class AudioDataModule(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        metadata: pd.DataFrame,\n",
    "        write_dir: str = \"./\",\n",
    "        data_dir: str = \"./\",\n",
    "        batch_size: int = 32,\n",
    "        num_workers: int = 8,\n",
    "        y_name=\"gs_score\",\n",
    "        trunc_pad_len=2048,\n",
    "        in_dim: int = 5,\n",
    "        seed: int = 42,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.metadata = metadata\n",
    "        self.write_dir = write_dir\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.y_name = y_name\n",
    "        self.trunc_pad_len = trunc_pad_len\n",
    "        self.in_dim = in_dim\n",
    "        self.num_workers = num_workers\n",
    "        self.seed = seed\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # Split out transcript metadata into train, val, test\n",
    "        rng = np.random.default_rng(42)\n",
    "        indices = rng.permutation(self.metadata.shape[0])\n",
    "        train_size = math.floor(len(indices) * 0.80)\n",
    "        val_size = math.floor(len(indices) * 0.10)\n",
    "        train_idx = indices[:train_size]\n",
    "        val_idx = indices[train_size : train_size + val_size]\n",
    "        test_idx = indices[train_size + val_size :]\n",
    "\n",
    "        self.train = self.metadata.iloc[train_idx].reset_index(drop=True)\n",
    "        self.train.to_csv(osp.join(self.write_dir, \"train.csv\"), index=False)\n",
    "\n",
    "        self.val = self.metadata.iloc[val_idx].reset_index(drop=True)\n",
    "        self.val.to_csv(osp.join(self.write_dir, \"val.csv\"), index=False)\n",
    "\n",
    "        self.test = self.metadata.iloc[test_idx].reset_index(drop=True)\n",
    "        self.test.to_csv(osp.join(self.write_dir, \"test.csv\"), index=False)\n",
    "\n",
    "    def setup(self):\n",
    "        # Load in train, val, test datasets\n",
    "        self.train_data = pd.read_csv(osp.join(self.write_dir, \"train.csv\"))\n",
    "        self.val_data = pd.read_csv(osp.join(self.write_dir, \"val.csv\"))\n",
    "        self.test_data = pd.read_csv(osp.join(self.write_dir, \"test.csv\"))\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            dataset=dl.AudioDataset(\n",
    "                metadata=self.train_data,\n",
    "                data_dir=self.data_dir,\n",
    "                y_name=self.y_name,\n",
    "                trunc_pad_len=self.trunc_pad_len,\n",
    "                in_dim=self.in_dim,\n",
    "            ),\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            dl.AudioDataset(\n",
    "                metadata=self.val_data,\n",
    "                data_dir=self.data_dir,\n",
    "                y_name=self.y_name,\n",
    "                trunc_pad_len=self.trunc_pad_len,\n",
    "                in_dim=self.in_dim,\n",
    "            ),\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            dl.AudioDataset(\n",
    "                metadata=self.test_data,\n",
    "                data_dir=self.data_dir,\n",
    "                y_name=self.y_name,\n",
    "                trunc_pad_len=self.trunc_pad_len,\n",
    "                in_dim=self.in_dim,\n",
    "            ),\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ebe6fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = AudioDataModule(\n",
    "    metadata=file_transcripts,\n",
    "    write_dir=write_dir,\n",
    "    data_dir=data_path,\n",
    "    batch_size=32,\n",
    "    num_workers=4,\n",
    "    y_name=\"gs_score\",\n",
    "    trunc_pad_len=sequence_len,\n",
    "    in_dim=5,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "datamodule.prepare_data()\n",
    "\n",
    "datamodule.setup()\n",
    "\n",
    "one_batch = next(iter(datamodule.train_dataloader()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4fe41b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([29, 2048, 5])\n",
      "torch.Size([29, 1])\n"
     ]
    }
   ],
   "source": [
    "print(one_batch[0].size())\n",
    "print(one_batch[1].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0acfc6",
   "metadata": {},
   "source": [
    "## Model Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31761870",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioFFModel(pl.LightningModule):\n",
    "    def __init__(self, input_dims=(2048, 5)):\n",
    "        super().__init__()\n",
    "        self.batch_norm = nn.BatchNorm1d(input_dims[0])\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.l1 = nn.Linear(input_dims[0] * input_dims[1], 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.l1(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch[0],batch[1]\n",
    "        y_hat = self(x)\n",
    "        loss = F.mse_loss(y_hat, y)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "082b3cb7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "C:\\Users\\yagne\\.conda\\envs\\grandstanding\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1579: UserWarning: GPU available but not used. Set the gpus flag in your trainer `Trainer(gpus=1)` or script `--gpus=1`.\n",
      "  rank_zero_warn(\n",
      "\n",
      "  | Name       | Type        | Params\n",
      "-------------------------------------------\n",
      "0 | batch_norm | BatchNorm1d | 4.1 K \n",
      "1 | flatten    | Flatten     | 0     \n",
      "2 | l1         | Linear      | 10.2 K\n",
      "-------------------------------------------\n",
      "14.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "14.3 K    Total params\n",
      "0.057     Total estimated model params size (MB)\n",
      "C:\\Users\\yagne\\.conda\\envs\\grandstanding\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:406: UserWarning: The number of training samples (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad94c28487814d63aab1314c4fa38b9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yagne\\.conda\\envs\\grandstanding\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:685: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer()\n",
    "model = AudioFFModel()\n",
    "trainer.fit(model, datamodule.train_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "80758874",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMRegressor(pl.LightningModule):\n",
    "    '''\n",
    "    Standard PyTorch Lightning module:\n",
    "    https://pytorch-lightning.readthedocs.io/en/latest/lightning_module.html\n",
    "    '''\n",
    "    def __init__(self, \n",
    "                 n_features, \n",
    "                 hidden_size, \n",
    "                 seq_len, \n",
    "                 batch_size,\n",
    "                 num_layers, \n",
    "                 dropout, \n",
    "                 learning_rate,\n",
    "                 criterion):\n",
    "        super(LSTMRegressor, self).__init__()\n",
    "        self.n_features = n_features\n",
    "        self.hidden_size = hidden_size\n",
    "        self.seq_len = seq_len\n",
    "        self.batch_size = batch_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        self.criterion = criterion\n",
    "        self.learning_rate = learning_rate\n",
    "        self.bn = nn.BatchNorm1d(n_features)\n",
    "        self.lstm = nn.LSTM(input_size=n_features, \n",
    "                            hidden_size=hidden_size,\n",
    "                            num_layers=num_layers, \n",
    "                            dropout=dropout, \n",
    "                            batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # lstm_out = (batch_size, seq_len, hidden_size)\n",
    "        x = x.permute(0,2,1)\n",
    "        x = self.bn(x)\n",
    "        x = x.permute(0,2,1)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        y_pred = self.linear(lstm_out[:,-1])\n",
    "        return y_pred\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log('val_loss', loss)\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log('test_loss', loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07c56b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "All parameters are aggregated in one place.\n",
    "This is useful for reporting experiment params to experiment tracking software\n",
    "'''\n",
    "\n",
    "p = dict(\n",
    "    seq_len = 2048,\n",
    "    batch_size = 32, \n",
    "    criterion = nn.MSELoss(),\n",
    "    max_epochs = 10,\n",
    "    n_features = 5,\n",
    "    hidden_size = 100,\n",
    "    num_layers = 1,\n",
    "    dropout = 0.2,\n",
    "    learning_rate = 0.001,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63f6c445",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1\n",
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name      | Type        | Params\n",
      "------------------------------------------\n",
      "0 | criterion | MSELoss     | 0     \n",
      "1 | bn        | BatchNorm1d | 10    \n",
      "2 | lstm      | LSTM        | 42.8 K\n",
      "3 | linear    | Linear      | 101   \n",
      "------------------------------------------\n",
      "42.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "42.9 K    Total params\n",
      "0.172     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3893669502dd4a75a7c1db511769f648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ade59f250334f7cafa1678cf5b0689d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_loss': 0.6769424080848694}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.6769424080848694}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_everything(1)\n",
    "\n",
    "csv_logger = CSVLogger('./', name='lstm', version='0'),\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=p['max_epochs'],\n",
    "    logger=csv_logger,\n",
    "    gpus=0,\n",
    "    progress_bar_refresh_rate=2,\n",
    ")\n",
    "\n",
    "model = LSTMRegressor(\n",
    "    n_features = p['n_features'],\n",
    "    hidden_size = p['hidden_size'],\n",
    "    seq_len = p['seq_len'],\n",
    "    batch_size = p['batch_size'],\n",
    "    criterion = p['criterion'],\n",
    "    num_layers = p['num_layers'],\n",
    "    dropout = p['dropout'],\n",
    "    learning_rate = p['learning_rate']\n",
    ")\n",
    "\n",
    "dm = AudioDataModule(\n",
    "    metadata=file_transcripts,\n",
    "    write_dir=write_dir,\n",
    "    data_dir=data_path,\n",
    "    batch_size=32,\n",
    "    num_workers=4,\n",
    "    y_name=\"gs_score\",\n",
    "    trunc_pad_len=sequence_len,\n",
    "    in_dim=5,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "dm.prepare_data()\n",
    "\n",
    "dm.setup()\n",
    "\n",
    "trainer.fit(model, dm)\n",
    "trainer.test(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640805a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
