{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Re-loads all imports every time the cell is ran. \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:,.5f}'.format\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "# Sklearn tools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Neural Networks\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "# from pytorch_lightning.loggers.csv_logs import CSVLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "# Plotting\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../scripts/\")\n",
    "import data_loader as dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/yagne/Downloads/household_power_consumption.txt/household_power_consumption.txt\n"
     ]
    }
   ],
   "source": [
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('C:/Users/yagne/Downloads/household_power_consumption.txt/'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeseriesDataset(Dataset):   \n",
    "    '''\n",
    "    Custom Dataset subclass. \n",
    "    Serves as input to DataLoader to transform X \n",
    "      into sequence data using rolling window. \n",
    "    DataLoader using this dataset will output batches \n",
    "      of `(batch_size, seq_len, n_features)` shape.\n",
    "    Suitable as an input to RNNs. \n",
    "    '''\n",
    "    def __init__(self, X: np.ndarray, y: np.ndarray, seq_len: int = 1):\n",
    "        self.X = torch.tensor(X).float()\n",
    "        self.y = torch.tensor(y).float()\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.__len__() - (self.seq_len-1)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.X[index:index+self.seq_len], self.y[index+self.seq_len-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PowerConsumptionDataModule(pl.LightningDataModule):\n",
    "    '''\n",
    "    PyTorch Lighting DataModule subclass:\n",
    "    https://pytorch-lightning.readthedocs.io/en/latest/datamodules.html\n",
    "\n",
    "    Serves the purpose of aggregating all data loading \n",
    "      and processing work in one place.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, path, seq_len = 1, batch_size = 128, num_workers=0):\n",
    "        super().__init__()\n",
    "        self.path = path\n",
    "        self.seq_len = seq_len\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "        self.X_val = None\n",
    "        self.y_val = None\n",
    "        self.X_test = None\n",
    "        self.X_test = None\n",
    "        self.columns = None\n",
    "        self.preprocessing = None\n",
    "\n",
    "    def prepare_data(self):\n",
    "        pass\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        '''\n",
    "        Data is resampled to hourly intervals.\n",
    "        Both 'np.nan' and '?' are converted to 'np.nan'\n",
    "        'Date' and 'Time' columns are merged into 'dt' index\n",
    "        '''\n",
    "\n",
    "        if stage == 'fit' and self.X_train is not None:\n",
    "            return \n",
    "        if stage == 'test' and self.X_test is not None:\n",
    "            return\n",
    "        if stage is None and self.X_train is not None and self.X_test is not None:  \n",
    "            return\n",
    "        \n",
    "        \n",
    "        df = pd.read_csv(\n",
    "            self.path, \n",
    "            sep=';', \n",
    "            parse_dates={'dt' : ['Date', 'Time']}, \n",
    "            infer_datetime_format=True, \n",
    "            low_memory=False, \n",
    "            na_values=['nan','?'], \n",
    "            index_col='dt'\n",
    "        )\n",
    "\n",
    "        df_resample = df.resample('h').mean()\n",
    "\n",
    "        X = df_resample.dropna().copy()\n",
    "        y = X['Global_active_power'].shift(-1).ffill()\n",
    "        self.columns = X.columns\n",
    "\n",
    "\n",
    "        X_cv, X_test, y_cv, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, shuffle=False\n",
    "        )\n",
    "    \n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_cv, y_cv, test_size=0.25, shuffle=False\n",
    "        )\n",
    "\n",
    "        preprocessing = StandardScaler()\n",
    "        preprocessing.fit(X_train)\n",
    "\n",
    "        if stage == 'fit' or stage is None:\n",
    "            self.X_train = preprocessing.transform(X_train)\n",
    "            self.y_train = y_train.values.reshape((-1, 1))\n",
    "            self.X_val = preprocessing.transform(X_val)\n",
    "            self.y_val = y_val.values.reshape((-1, 1))\n",
    "\n",
    "        if stage == 'test' or stage is None:\n",
    "            self.X_test = preprocessing.transform(X_test)\n",
    "            self.y_test = y_test.values.reshape((-1, 1))\n",
    "        \n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train_dataset = dl.TimeseriesDataset(self.X_train, \n",
    "                                          self.y_train, \n",
    "                                          seq_len=self.seq_len)\n",
    "        train_loader = DataLoader(train_dataset, \n",
    "                                  batch_size = self.batch_size, \n",
    "                                  shuffle = False, \n",
    "                                  num_workers = self.num_workers)\n",
    "        \n",
    "        return train_loader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        val_dataset = dl.TimeseriesDataset(self.X_val, \n",
    "                                        self.y_val, \n",
    "                                        seq_len=self.seq_len)\n",
    "        val_loader = DataLoader(val_dataset, \n",
    "                                batch_size = self.batch_size, \n",
    "                                shuffle = False, \n",
    "                                num_workers = self.num_workers)\n",
    "\n",
    "        return val_loader\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        test_dataset = dl.TimeseriesDataset(self.X_test, \n",
    "                                         self.y_test, \n",
    "                                         seq_len=self.seq_len)\n",
    "        test_loader = DataLoader(test_dataset, \n",
    "                                 batch_size = self.batch_size, \n",
    "                                 shuffle = False, \n",
    "                                 num_workers = self.num_workers)\n",
    "\n",
    "        return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMRegressor(pl.LightningModule):\n",
    "    '''\n",
    "    Standard PyTorch Lightning module:\n",
    "    https://pytorch-lightning.readthedocs.io/en/latest/lightning_module.html\n",
    "    '''\n",
    "    def __init__(self, \n",
    "                 n_features, \n",
    "                 hidden_size, \n",
    "                 seq_len, \n",
    "                 batch_size,\n",
    "                 num_layers, \n",
    "                 dropout, \n",
    "                 learning_rate,\n",
    "                 criterion):\n",
    "        super(LSTMRegressor, self).__init__()\n",
    "        self.n_features = n_features\n",
    "        self.hidden_size = hidden_size\n",
    "        self.seq_len = seq_len\n",
    "        self.batch_size = batch_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        self.criterion = criterion\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=n_features, \n",
    "                            hidden_size=hidden_size,\n",
    "                            num_layers=num_layers, \n",
    "                            dropout=dropout, \n",
    "                            batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # lstm_out = (batch_size, seq_len, hidden_size)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        y_pred = self.linear(lstm_out[:,-1])\n",
    "        return y_pred\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log('val_loss', loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log('test_loss', loss, prog_bar=True, logger=True)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "All parameters are aggregated in one place.\n",
    "This is useful for reporting experiment params to experiment tracking software\n",
    "'''\n",
    "\n",
    "p = dict(\n",
    "    seq_len = 24,\n",
    "    batch_size = 1024, \n",
    "    criterion = nn.MSELoss(),\n",
    "    num_workers = 4,\n",
    "    max_epochs = 50,\n",
    "    n_features = 7,\n",
    "    hidden_size = 128,\n",
    "    num_layers = 2,\n",
    "    dropout = 0.2,\n",
    "    learning_rate = 0.001,\n",
    "    path=\"C:/Users/yagne/Downloads/household_power_consumption.txt/household_power_consumption.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 15684), started 0:00:23 ago. (Use '!kill 15684' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-debd9a5b3ae162a9\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-debd9a5b3ae162a9\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yagne\\.conda\\envs\\grandstanding\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\callback_connector.py:147: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=<pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint object at 0x00000264B36F20D0>)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=<pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint object at 0x00000264B36F20D0>)`.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "# seed_everything(1)\n",
    "\n",
    "# csv_logger = CSVLogger('./', name='lstm'),\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath = \"checkpoints\",\n",
    "    filename = \"best-checkpoint\", \n",
    "    save_top_k=1, \n",
    "    verbose =True, \n",
    "    monitor = \"val_loss\",\n",
    "    mode=\"min\"\n",
    ")\n",
    "\n",
    "\n",
    "logger = TensorBoardLogger(\"lstm\", name=\"kaggle_example\")\n",
    "early_stopping_callback = EarlyStopping(monitor=\"val_loss\", patience = 10)\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=p['max_epochs'],\n",
    "    logger=logger,\n",
    "    gpus=1,\n",
    "    checkpoint_callback=checkpoint_callback,\n",
    "    callbacks = [early_stopping_callback],\n",
    ")\n",
    "\n",
    "model = LSTMRegressor(\n",
    "    n_features = p['n_features'],\n",
    "    hidden_size = p['hidden_size'],\n",
    "    seq_len = p['seq_len'],\n",
    "    batch_size = p['batch_size'],\n",
    "    criterion = p['criterion'],\n",
    "    num_layers = p['num_layers'],\n",
    "    dropout = p['dropout'],\n",
    "    learning_rate = p['learning_rate']\n",
    ")\n",
    "\n",
    "dm = PowerConsumptionDataModule(\n",
    "    path=p[\"path\"],\n",
    "    seq_len = p['seq_len'],\n",
    "    batch_size = p['batch_size'],\n",
    "    num_workers = p[\"num_workers\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yagne\\.conda\\envs\\grandstanding\\lib\\site-packages\\pytorch_lightning\\core\\datamodule.py:469: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
      "  rank_zero_deprecation(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor([[[ 0.5238,  1.3351, -0.8441,  ..., -0.3239, -0.3128,  1.7411],\n",
       "          [-0.1272,  0.4233, -0.4469,  ..., -0.3239, -0.1902, -0.0191],\n",
       "          [-0.4293, -0.2587, -0.0095,  ..., -0.3239, -0.3128, -0.0624],\n",
       "          ...,\n",
       "          [ 0.3451, -0.9257, -0.2844,  ..., -0.3239, -0.3128,  1.7843],\n",
       "          [ 0.4715,  0.8245, -0.4566,  ..., -0.3239, -0.1938,  1.7661],\n",
       "          [ 0.4700,  1.7367,  0.5705,  ..., -0.3239, -0.3128,  1.7047]],\n",
       " \n",
       "         [[-0.1272,  0.4233, -0.4469,  ..., -0.3239, -0.1902, -0.0191],\n",
       "          [-0.4293, -0.2587, -0.0095,  ..., -0.3239, -0.3128, -0.0624],\n",
       "          [-0.4399,  0.1564,  0.1259,  ..., -0.3239, -0.1902, -0.0191],\n",
       "          ...,\n",
       "          [ 0.4715,  0.8245, -0.4566,  ..., -0.3239, -0.1938,  1.7661],\n",
       "          [ 0.4700,  1.7367,  0.5705,  ..., -0.3239, -0.3128,  1.7047],\n",
       "          [ 1.0761,  2.8870,  0.0285,  ...,  1.8750, -0.2010,  1.7888]],\n",
       " \n",
       "         [[-0.4293, -0.2587, -0.0095,  ..., -0.3239, -0.3128, -0.0624],\n",
       "          [-0.4399,  0.1564,  0.1259,  ..., -0.3239, -0.1902, -0.0191],\n",
       "          [-0.8086, -0.7641,  0.6258,  ..., -0.3239, -0.3128, -0.7423],\n",
       "          ...,\n",
       "          [ 0.4700,  1.7367,  0.5705,  ..., -0.3239, -0.3128,  1.7047],\n",
       "          [ 1.0761,  2.8870,  0.0285,  ...,  1.8750, -0.2010,  1.7888],\n",
       "          [ 1.2181,  4.0553,  0.1910,  ...,  2.0630, -0.3020,  1.8070]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-0.8619, -0.5282,  0.4737,  ..., -0.3239, -0.3128, -0.6855],\n",
       "          [-0.7664,  0.9747,  0.7770,  ..., -0.3239, -0.1721, -0.6082],\n",
       "          [-0.8205, -0.2282,  0.9021,  ..., -0.3239, -0.3128, -0.6104],\n",
       "          ...,\n",
       "          [ 0.8088, -0.0744, -0.0901,  ..., -0.3239, -0.2876,  1.6797],\n",
       "          [-0.4573,  1.1342,  0.3601,  ..., -0.3239, -0.1721, -0.6173],\n",
       "          [-0.7650,  0.0939,  0.7153,  ..., -0.3239, -0.3092, -0.6059]],\n",
       " \n",
       "         [[-0.7664,  0.9747,  0.7770,  ..., -0.3239, -0.1721, -0.6082],\n",
       "          [-0.8205, -0.2282,  0.9021,  ..., -0.3239, -0.3128, -0.6104],\n",
       "          [-0.7673,  0.6773,  0.9592,  ..., -0.3239, -0.1721, -0.5991],\n",
       "          ...,\n",
       "          [-0.4573,  1.1342,  0.3601,  ..., -0.3239, -0.1721, -0.6173],\n",
       "          [-0.7650,  0.0939,  0.7153,  ..., -0.3239, -0.3092, -0.6059],\n",
       "          [-0.9167,  0.2349,  0.0112,  ..., -0.3239, -0.1721, -0.7446]],\n",
       " \n",
       "         [[-0.8205, -0.2282,  0.9021,  ..., -0.3239, -0.3128, -0.6104],\n",
       "          [-0.7673,  0.6773,  0.9592,  ..., -0.3239, -0.1721, -0.5991],\n",
       "          [-0.5063, -0.3465,  1.0839,  ..., -0.3239, -0.3128,  0.0650],\n",
       "          ...,\n",
       "          [-0.7650,  0.0939,  0.7153,  ..., -0.3239, -0.3092, -0.6059],\n",
       "          [-0.9167,  0.2349,  0.0112,  ..., -0.3239, -0.1721, -0.7446],\n",
       "          [-0.9061, -0.5958,  0.1671,  ..., -0.3239, -0.3128, -0.6127]]]),\n",
       " tensor([[2.1674],\n",
       "         [2.3041],\n",
       "         [1.5480],\n",
       "         ...,\n",
       "         [0.2497],\n",
       "         [0.2599],\n",
       "         [0.3223]])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm.setup()\n",
    "next(iter(dm.val_dataloader()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics = pd.read_csv('./lstm/version_2/metrics.csv')\n",
    "# train_loss = metrics[['train_loss', 'step', 'epoch']][~np.isnan(metrics['train_loss'])]\n",
    "# val_loss = metrics[['val_loss', 'epoch']][~np.isnan(metrics['val_loss'])]\n",
    "# test_loss = metrics['test_loss'].iloc[-1]\n",
    "\n",
    "# fig, axes = plt.subplots(1, 2, figsize=(16, 5), dpi=100)\n",
    "# axes[0].set_title('Train loss per batch')\n",
    "# axes[0].plot(train_loss['step'], train_loss['train_loss'])\n",
    "# axes[1].set_title('Validation loss per epoch')\n",
    "# axes[1].plot(val_loss['epoch'], val_loss['val_loss'], color='orange')\n",
    "# plt.show(block = True)\n",
    "\n",
    "# print('MSE:')\n",
    "# print(f\"Train loss: {train_loss['train_loss'].iloc[-1]:.3f}\")\n",
    "# print(f\"Val loss:   {val_loss['val_loss'].iloc[-1]:.3f}\")\n",
    "# print(f'Test loss:  {test_loss:.3f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = next(iter(dm.train_dataloader()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  torch.Size([128, 24, 7])\n",
      "y:  torch.Size([128, 1])\n"
     ]
    }
   ],
   "source": [
    "print(\"X: \", a[0].size())\n",
    "print(\"y: \", a[1].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "            p[\"path\"], \n",
    "            sep=';', \n",
    "            parse_dates={'dt' : ['Date', 'Time']}, \n",
    "            infer_datetime_format=True, \n",
    "            low_memory=False, \n",
    "            na_values=['nan','?'], \n",
    "            index_col='dt'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2075259, 7)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Global_active_power</th>\n",
       "      <th>Global_reactive_power</th>\n",
       "      <th>Voltage</th>\n",
       "      <th>Global_intensity</th>\n",
       "      <th>Sub_metering_1</th>\n",
       "      <th>Sub_metering_2</th>\n",
       "      <th>Sub_metering_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:24:00</th>\n",
       "      <td>4.21600</td>\n",
       "      <td>0.41800</td>\n",
       "      <td>234.84000</td>\n",
       "      <td>18.40000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>17.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:25:00</th>\n",
       "      <td>5.36000</td>\n",
       "      <td>0.43600</td>\n",
       "      <td>233.63000</td>\n",
       "      <td>23.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>16.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:26:00</th>\n",
       "      <td>5.37400</td>\n",
       "      <td>0.49800</td>\n",
       "      <td>233.29000</td>\n",
       "      <td>23.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>17.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:27:00</th>\n",
       "      <td>5.38800</td>\n",
       "      <td>0.50200</td>\n",
       "      <td>233.74000</td>\n",
       "      <td>23.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>17.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:28:00</th>\n",
       "      <td>3.66600</td>\n",
       "      <td>0.52800</td>\n",
       "      <td>235.68000</td>\n",
       "      <td>15.80000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>17.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Global_active_power  Global_reactive_power   Voltage  \\\n",
       "dt                                                                          \n",
       "2006-12-16 17:24:00              4.21600                0.41800 234.84000   \n",
       "2006-12-16 17:25:00              5.36000                0.43600 233.63000   \n",
       "2006-12-16 17:26:00              5.37400                0.49800 233.29000   \n",
       "2006-12-16 17:27:00              5.38800                0.50200 233.74000   \n",
       "2006-12-16 17:28:00              3.66600                0.52800 235.68000   \n",
       "\n",
       "                     Global_intensity  Sub_metering_1  Sub_metering_2  \\\n",
       "dt                                                                      \n",
       "2006-12-16 17:24:00          18.40000         0.00000         1.00000   \n",
       "2006-12-16 17:25:00          23.00000         0.00000         1.00000   \n",
       "2006-12-16 17:26:00          23.00000         0.00000         2.00000   \n",
       "2006-12-16 17:27:00          23.00000         0.00000         1.00000   \n",
       "2006-12-16 17:28:00          15.80000         0.00000         1.00000   \n",
       "\n",
       "                     Sub_metering_3  \n",
       "dt                                   \n",
       "2006-12-16 17:24:00        17.00000  \n",
       "2006-12-16 17:25:00        16.00000  \n",
       "2006-12-16 17:26:00        17.00000  \n",
       "2006-12-16 17:27:00        17.00000  \n",
       "2006-12-16 17:28:00        17.00000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2,075,259\n"
     ]
    }
   ],
   "source": [
    "print(f\"{2075259:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resample = df.resample('h').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Global_active_power</th>\n",
       "      <th>Global_reactive_power</th>\n",
       "      <th>Voltage</th>\n",
       "      <th>Global_intensity</th>\n",
       "      <th>Sub_metering_1</th>\n",
       "      <th>Sub_metering_2</th>\n",
       "      <th>Sub_metering_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:00:00</th>\n",
       "      <td>4.22289</td>\n",
       "      <td>0.22900</td>\n",
       "      <td>234.64389</td>\n",
       "      <td>18.10000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.52778</td>\n",
       "      <td>16.86111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 18:00:00</th>\n",
       "      <td>3.63220</td>\n",
       "      <td>0.08003</td>\n",
       "      <td>234.58017</td>\n",
       "      <td>15.60000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>6.71667</td>\n",
       "      <td>16.86667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 19:00:00</th>\n",
       "      <td>3.40023</td>\n",
       "      <td>0.08523</td>\n",
       "      <td>233.23250</td>\n",
       "      <td>14.50333</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.43333</td>\n",
       "      <td>16.68333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 20:00:00</th>\n",
       "      <td>3.26857</td>\n",
       "      <td>0.07510</td>\n",
       "      <td>234.07150</td>\n",
       "      <td>13.91667</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>16.78333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 21:00:00</th>\n",
       "      <td>3.05647</td>\n",
       "      <td>0.07667</td>\n",
       "      <td>237.15867</td>\n",
       "      <td>13.04667</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.41667</td>\n",
       "      <td>17.21667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Global_active_power  Global_reactive_power   Voltage  \\\n",
       "dt                                                                          \n",
       "2006-12-16 17:00:00              4.22289                0.22900 234.64389   \n",
       "2006-12-16 18:00:00              3.63220                0.08003 234.58017   \n",
       "2006-12-16 19:00:00              3.40023                0.08523 233.23250   \n",
       "2006-12-16 20:00:00              3.26857                0.07510 234.07150   \n",
       "2006-12-16 21:00:00              3.05647                0.07667 237.15867   \n",
       "\n",
       "                     Global_intensity  Sub_metering_1  Sub_metering_2  \\\n",
       "dt                                                                      \n",
       "2006-12-16 17:00:00          18.10000         0.00000         0.52778   \n",
       "2006-12-16 18:00:00          15.60000         0.00000         6.71667   \n",
       "2006-12-16 19:00:00          14.50333         0.00000         1.43333   \n",
       "2006-12-16 20:00:00          13.91667         0.00000         0.00000   \n",
       "2006-12-16 21:00:00          13.04667         0.00000         0.41667   \n",
       "\n",
       "                     Sub_metering_3  \n",
       "dt                                   \n",
       "2006-12-16 17:00:00        16.86111  \n",
       "2006-12-16 18:00:00        16.86667  \n",
       "2006-12-16 19:00:00        16.68333  \n",
       "2006-12-16 20:00:00        16.78333  \n",
       "2006-12-16 21:00:00        17.21667  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6092a9a14935c0fda91fba9e22a173e78eada2dccd73d5f4bfbae38f5a7c8b38"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
