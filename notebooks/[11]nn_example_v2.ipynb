{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-loads all imports every time the cell is ran. \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from time import time\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:,.5f}'.format\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "# Sklearn tools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Neural Networks\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "# from pytorch_lightning.loggers.csv_logs import CSVLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "# Plotting\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../scripts/\")\n",
    "import data_loader as dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/yagne/Downloads/household_power_consumption.txt/household_power_consumption.txt\n"
     ]
    }
   ],
   "source": [
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "import os\n",
    "import os.path as osp\n",
    "for dirname, _, filenames in os.walk('C:/Users/yagne/Downloads/household_power_consumption.txt/'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewAudioDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 metadata,\n",
    "                 data_maxes = np.load(\"../outputs/data_maxes.npy\"),\n",
    "                 data_directory=\"../outputs/npy2\",\n",
    "                 num_features: int = 5,\n",
    "                 seq_len: int = 2048,\n",
    "                 y_col=\"gs_score\"):\n",
    "        self.metadata = metadata\n",
    "        self.columns_dict = dict([(c, i) for i, c in enumerate(self.metadata.columns)])\n",
    "        self.data_maxes = data_maxes\n",
    "        self.data_directory = data_directory\n",
    "        self.num_features = num_features\n",
    "        self.seq_len = seq_len\n",
    "        self.y_col = \"gs_score\"\n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        row = self.metadata.iloc[index]\n",
    "        # means_stds = [c for c in self.columns_dict.keys() if (\"mean\" in c) or (\"std\" in c)]\n",
    "        file_name = row[self.columns_dict[\"file\"]]\n",
    "        line_name = row[self.columns_dict[\"line\"]]\n",
    "        npy_path = osp.join(self.data_directory, f\"{file_name}_{line_name}.npy\")\n",
    "        data = np.load(npy_path)\n",
    "        data = data/self.data_maxes\n",
    "        \n",
    "        # Get y_true\n",
    "        score = row[self.columns_dict[self.y_col]]\n",
    "#         score = score.reshape(-1,1)\n",
    "        \n",
    "        data_aug = np.zeros((self.seq_len, self.num_features))\n",
    "\n",
    "        data_aug[: min(data.shape[0], self.seq_len), :] = data[\n",
    "            : self.seq_len\n",
    "        ]\n",
    "        \n",
    "        item = {\n",
    "            \"x\": torch.tensor(data_aug, dtype=torch.float),\n",
    "            \"y\": torch.tensor(score, dtype=torch.float),\n",
    "        }\n",
    "\n",
    "        return (item[\"x\"], item[\"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17110\n",
      "(tensor([[0.0000, 0.0000, 0.0100, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0100, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0100, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]), tensor(-1.1736))\n",
      "(tensor([[0.0000, 0.0000, 0.0100, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0100, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0100, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]), tensor(-0.8314))\n",
      "(tensor([[0.0000, 0.0000, 0.0100, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0100, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0100, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]), tensor(0.7401))\n",
      "(tensor([[0.0000, 0.0000, 0.0561, 0.0000, 0.0000],\n",
      "        [0.9317, 1.0000, 0.0100, 0.0000, 0.0000],\n",
      "        [0.9021, 1.0000, 0.1086, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]), tensor(0.3268))\n"
     ]
    }
   ],
   "source": [
    "transcripts = pd.read_csv(\"../outputs/valid_transcripts.csv\")\n",
    "it = iter(NewAudioDataset(transcripts))\n",
    "print(NewAudioDataset(transcripts).__len__())\n",
    "print(next(it))\n",
    "print(next(it))\n",
    "print(next(it))\n",
    "print(next(it))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewAudioDataModule(pl.LightningDataModule):\n",
    "    def __init__(self,\n",
    "                 metadata,\n",
    "                 data_maxes = np.load(\"../outputs/data_maxes.npy\"),\n",
    "                 split_directory=\"../outputs/splits\",\n",
    "                 data_directory=\"../outputs/npy2\",\n",
    "                 seq_len=2048,\n",
    "                 num_features=5,\n",
    "                 y_col=\"gs_score\",\n",
    "                 batch_size=128,\n",
    "                 num_workers=4,\n",
    "                 seed=42\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.metadata = metadata\n",
    "        self.data_maxes = data_maxes\n",
    "        self.split_directory = split_directory\n",
    "        self.data_directory = data_directory\n",
    "        self.seq_len = seq_len\n",
    "        self.num_features = num_features\n",
    "        self.y_col = y_col\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.seed = seed\n",
    "        \n",
    "    def prepare_data(self):\n",
    "        rng = np.random.default_rng(self.seed)\n",
    "        indices = rng.permutation(self.metadata.shape[0])\n",
    "        train_size = math.floor(len(indices) * 0.80)\n",
    "        val_size = math.floor(len(indices) * 0.10)\n",
    "        train_idx = indices[:train_size]\n",
    "        val_idx = indices[train_size : train_size + val_size]\n",
    "        test_idx = indices[train_size + val_size :]\n",
    "    \n",
    "        self.train = self.metadata.iloc[train_idx].reset_index(drop=True)\n",
    "        self.train.to_csv(osp.join(self.split_directory, \"train.csv\"), index=False)\n",
    "\n",
    "        self.val = self.metadata.iloc[val_idx].reset_index(drop=True)\n",
    "        self.val.to_csv(osp.join(self.split_directory, \"val.csv\"), index=False)\n",
    "\n",
    "        self.test = self.metadata.iloc[test_idx].reset_index(drop=True)\n",
    "        self.test.to_csv(osp.join(self.split_directory, \"test.csv\"), index=False)\n",
    "        \n",
    "    def setup(self):\n",
    "        self.train_data = pd.read_csv(osp.join(self.split_directory, \"train.csv\"))\n",
    "        self.val_data = pd.read_csv(osp.join(self.split_directory, \"val.csv\"))\n",
    "        self.test_data = pd.read_csv(osp.join(self.split_directory, \"test.csv\"))\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        self.train_dataset = dl.NewAudioDataset(metadata=self.train_data,\n",
    "            data_maxes = self.data_maxes,\n",
    "            data_directory=self.data_directory,\n",
    "            num_features= self.num_features,\n",
    "            seq_len = self.seq_len,\n",
    "            y_col=self.y_col)\n",
    "        train_loader = DataLoader(self.train_dataset, \n",
    "                                  batch_size = self.batch_size, \n",
    "                                  shuffle = False, \n",
    "                                  num_workers = self.num_workers)\n",
    "        \n",
    "        return train_loader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        self.val_dataset = dl.NewAudioDataset(metadata=self.val_data,\n",
    "            data_maxes = self.data_maxes,\n",
    "            data_directory=self.data_directory,\n",
    "            num_features= self.num_features,\n",
    "            seq_len = self.seq_len,\n",
    "            y_col=self.y_col)\n",
    "        val_loader = DataLoader(self.val_dataset, \n",
    "                                batch_size = self.batch_size, \n",
    "                                shuffle = False, \n",
    "                                num_workers = self.num_workers)\n",
    "\n",
    "        return val_loader\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        self.test_dataset = dl.NewAudioDataset(\n",
    "            metadata=self.test_data,\n",
    "            data_maxes = self.data_maxes,\n",
    "            data_directory=self.data_directory,\n",
    "            num_features= self.num_features,\n",
    "            seq_len = self.seq_len,\n",
    "            y_col=self.y_col)\n",
    "        test_loader = DataLoader(self.test_dataset, \n",
    "                                 batch_size = self.batch_size, \n",
    "                                 shuffle = False, \n",
    "                                 num_workers = self.num_workers)\n",
    "\n",
    "        return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcripts = pd.read_csv(\"../outputs/valid_transcripts.csv\")\n",
    "\n",
    "\n",
    "dm = NewAudioDataModule(metadata=transcripts,\n",
    "    data_maxes = np.load(\"../outputs/data_maxes.npy\"),                    \n",
    "    split_directory=\"../outputs/splits\",\n",
    "    data_directory=\"../outputs/npy2\",\n",
    "    seq_len=2048,\n",
    "    num_features=5,\n",
    "    y_col=\"gs_score\",\n",
    "    batch_size=128,\n",
    "    num_workers=4,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "dm.prepare_data()\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = next(iter(dm.test_dataloader()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0897],\n",
       "        [-1.0980],\n",
       "        [-0.4058],\n",
       "        [ 0.2149],\n",
       "        [ 0.4949],\n",
       "        [ 1.1137],\n",
       "        [-0.8485],\n",
       "        [ 0.4415],\n",
       "        [ 0.1394],\n",
       "        [ 0.9759],\n",
       "        [ 0.8286],\n",
       "        [ 1.0672],\n",
       "        [-0.5937],\n",
       "        [-0.1836],\n",
       "        [-0.6085],\n",
       "        [ 0.0931],\n",
       "        [ 0.2375],\n",
       "        [ 0.2525],\n",
       "        [ 0.4784],\n",
       "        [-0.1702],\n",
       "        [-0.9899],\n",
       "        [ 0.2278],\n",
       "        [ 0.4687],\n",
       "        [-0.1692],\n",
       "        [ 0.0160],\n",
       "        [-1.6187],\n",
       "        [ 0.5862],\n",
       "        [-1.4173],\n",
       "        [-0.1363],\n",
       "        [ 0.0659],\n",
       "        [ 0.1783],\n",
       "        [-0.5699],\n",
       "        [ 0.2688],\n",
       "        [-0.1328],\n",
       "        [ 0.8270],\n",
       "        [ 0.6541],\n",
       "        [ 0.9794],\n",
       "        [-0.4515],\n",
       "        [-0.1409],\n",
       "        [ 0.3374],\n",
       "        [-1.3745],\n",
       "        [-0.4433],\n",
       "        [-0.3409],\n",
       "        [ 0.2464],\n",
       "        [ 0.8267],\n",
       "        [ 0.3802],\n",
       "        [ 0.2278],\n",
       "        [-1.2297],\n",
       "        [ 0.3120],\n",
       "        [-0.3844],\n",
       "        [-0.6961],\n",
       "        [ 0.4879],\n",
       "        [-0.6369],\n",
       "        [ 0.1024],\n",
       "        [ 1.3804],\n",
       "        [ 0.7826],\n",
       "        [ 1.0909],\n",
       "        [ 0.5710],\n",
       "        [ 0.6853],\n",
       "        [ 0.0400],\n",
       "        [ 0.8822],\n",
       "        [-0.8547],\n",
       "        [ 0.6928],\n",
       "        [-0.3008],\n",
       "        [-0.2480],\n",
       "        [ 1.1684],\n",
       "        [ 0.6574],\n",
       "        [ 0.1413],\n",
       "        [-1.6253],\n",
       "        [ 0.1758],\n",
       "        [-0.1259],\n",
       "        [ 0.1056],\n",
       "        [-1.2056],\n",
       "        [-0.7172],\n",
       "        [-0.6855],\n",
       "        [-0.1434],\n",
       "        [-0.7776],\n",
       "        [ 0.2251],\n",
       "        [-0.6625],\n",
       "        [ 0.4623],\n",
       "        [ 0.0583],\n",
       "        [-1.1925],\n",
       "        [ 0.9882],\n",
       "        [ 0.6817],\n",
       "        [-0.1112],\n",
       "        [-0.2297],\n",
       "        [ 0.5378],\n",
       "        [ 0.5271],\n",
       "        [-0.5329],\n",
       "        [ 0.4267],\n",
       "        [ 0.6853],\n",
       "        [ 0.5136],\n",
       "        [ 0.4753],\n",
       "        [ 0.2080],\n",
       "        [ 0.5775],\n",
       "        [-0.2272],\n",
       "        [ 0.2844],\n",
       "        [-0.6368],\n",
       "        [ 0.4296],\n",
       "        [-0.1453],\n",
       "        [ 0.5956],\n",
       "        [ 0.4883],\n",
       "        [ 0.3735],\n",
       "        [ 0.5716],\n",
       "        [-0.8128],\n",
       "        [-0.5761],\n",
       "        [-0.1074],\n",
       "        [ 0.5663],\n",
       "        [-1.1605],\n",
       "        [-0.2577],\n",
       "        [ 0.1832],\n",
       "        [-0.1107],\n",
       "        [-0.8771],\n",
       "        [-0.1239],\n",
       "        [ 0.0547],\n",
       "        [ 0.4256],\n",
       "        [-0.6669],\n",
       "        [ 0.2983],\n",
       "        [-0.9194],\n",
       "        [ 0.7030],\n",
       "        [-0.5527],\n",
       "        [ 0.1333],\n",
       "        [-1.1539],\n",
       "        [ 0.6448],\n",
       "        [ 0.3613],\n",
       "        [-1.7639],\n",
       "        [ 0.0409],\n",
       "        [ 0.1492]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[1].unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMRegressor(pl.LightningModule):\n",
    "    '''\n",
    "    Standard PyTorch Lightning module:\n",
    "    https://pytorch-lightning.readthedocs.io/en/latest/lightning_module.html\n",
    "    '''\n",
    "    def __init__(self, \n",
    "                 n_features, \n",
    "                 hidden_size, \n",
    "                 seq_len, \n",
    "                 batch_size,\n",
    "                 num_layers, \n",
    "                 dropout, \n",
    "                 learning_rate,\n",
    "                 criterion):\n",
    "        super(LSTMRegressor, self).__init__()\n",
    "        self.n_features = n_features\n",
    "        self.hidden_size = hidden_size\n",
    "        self.seq_len = seq_len\n",
    "        self.batch_size = batch_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        self.criterion = criterion\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=n_features, \n",
    "                            hidden_size=hidden_size,\n",
    "                            num_layers=num_layers, \n",
    "                            dropout=dropout, \n",
    "                            batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # lstm_out = (batch_size, seq_len, hidden_size)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        y_pred = self.linear(lstm_out[:,-1])\n",
    "        return y_pred\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y = y.unsqueeze(1)\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y = y.unsqueeze(1)\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log('val_loss', loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y = y.unsqueeze(1)\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log('test_loss', loss, prog_bar=True, logger=True)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "All parameters are aggregated in one place.\n",
    "This is useful for reporting experiment params to experiment tracking software\n",
    "'''\n",
    "\n",
    "p = dict(\n",
    "    seq_len = 2048,\n",
    "    batch_size = 64, \n",
    "    criterion = nn.MSELoss(),\n",
    "    num_workers = 4,\n",
    "    max_epochs = 50,\n",
    "    n_features = 5,\n",
    "    hidden_size = 128,\n",
    "    num_layers = 2,\n",
    "    dropout = 0.2,\n",
    "    learning_rate = 0.0001,\n",
    "    path=\"C:/Users/yagne/Downloads/household_power_consumption.txt/household_power_consumption.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 17040), started 1 day, 4:57:22 ago. (Use '!kill 17040' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-406bba385e464aef\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-406bba385e464aef\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yagne\\.conda\\envs\\grandstanding\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\callback_connector.py:147: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=<pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint object at 0x000002649C955D90>)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=<pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint object at 0x000002649C955D90>)`.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "C:\\Users\\yagne\\.conda\\envs\\grandstanding\\lib\\site-packages\\pytorch_lightning\\core\\datamodule.py:469: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
      "  rank_zero_deprecation(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type    | Params\n",
      "--------------------------------------\n",
      "0 | criterion | MSELoss | 0     \n",
      "1 | lstm      | LSTM    | 201 K \n",
      "2 | linear    | Linear  | 129   \n",
      "--------------------------------------\n",
      "201 K     Trainable params\n",
      "0         Non-trainable params\n",
      "201 K     Total params\n",
      "0.805     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b43a388c20d441c9b26b1b7ab95c321",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a21162edd2a24e9eb1b9b381b95035ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_loss': 0.45311039686203003}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.45311039686203003}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seed_everything(1)\n",
    "\n",
    "# csv_logger = CSVLogger('./', name='lstm'),\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath = \"checkpoints\",\n",
    "    filename = \"best-checkpoint\", \n",
    "    save_top_k=1, \n",
    "    verbose =True, \n",
    "    monitor = \"val_loss\",\n",
    "    mode=\"min\"\n",
    ")\n",
    "\n",
    "\n",
    "logger = TensorBoardLogger(\"lstm\", name=\"audio_change\")\n",
    "early_stopping_callback = EarlyStopping(monitor=\"val_loss\", patience = 4)\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=p['max_epochs'],\n",
    "    logger=logger,\n",
    "    gpus=1,\n",
    "    checkpoint_callback=checkpoint_callback,\n",
    "    callbacks = [early_stopping_callback],\n",
    "#     overfit_batches=1\n",
    ")\n",
    "\n",
    "model = LSTMRegressor(\n",
    "    n_features = p['n_features'],\n",
    "    hidden_size = p['hidden_size'],\n",
    "    seq_len = p['seq_len'],\n",
    "    batch_size = p['batch_size'],\n",
    "    criterion = p['criterion'],\n",
    "    num_layers = p['num_layers'],\n",
    "    dropout = p['dropout'],\n",
    "    learning_rate = p['learning_rate']\n",
    ")\n",
    "\n",
    "dm = NewAudioDataModule(metadata=transcripts,\n",
    "    data_maxes = np.load(\"../outputs/data_maxes.npy\"),                    \n",
    "    split_directory=\"../outputs/splits\",\n",
    "    data_directory=\"../outputs/npy2\",\n",
    "    seq_len=2048,\n",
    "    num_features=5,\n",
    "    y_col=\"gs_score\",\n",
    "    batch_size=128,\n",
    "    num_workers=4,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "dm.setup()\n",
    "dm.prepare_data()\n",
    "\n",
    "trainer.fit(model, dm)\n",
    "trainer.test(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6092a9a14935c0fda91fba9e22a173e78eada2dccd73d5f4bfbae38f5a7c8b38"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
