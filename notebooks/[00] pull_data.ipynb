{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import requests\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arguments and User Defined Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = (\"2013\", \"2020\")  # Years of cases to collection, Inclusive, Strings\n",
    "n_limit = 5  # For debugging purposes, leave as `None`` otherwise.\n",
    "cluster_shell_start = None  # Specific to the environment working on.\n",
    "# cluster_shell_start = [\n",
    "#         \"#!/bin/bash \\n\",\n",
    "#         \"#SBATCH --nodes=1 \\n\",\n",
    "#         \"#SBATCH --ntasks-per-node=1 \\n\",\n",
    "#         \"#SBATCH --cpus-per-task=1 \\n\",\n",
    "#         \"#SBATCH --time=5:00:00 \\n\",\n",
    "#         \"#SBATCH --mem=2GB \\n\",\n",
    "#         \"#SBATCH --job-name=get_oyez_mp3s \\n\",\n",
    "#         \"\\n\",\n",
    "#     ]\n",
    "mp3_output_dir = \"../outputs/mp3s/\"  # Include ending backslash\n",
    "wav_output_dir = \"../outputs/wavs/\"  # Include ending backslash\n",
    "if not os.path.exists(mp3_output_dir):\n",
    "    os.makedirs(mp3_output_dir)\n",
    "if not os.path.exists(wav_output_dir):\n",
    "    os.makedirs(wav_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_http_json(url):\n",
    "    # print(f\"Getting {url}\")\n",
    "    response = requests.get(url)\n",
    "    parsed = response.json()\n",
    "    return parsed\n",
    "\n",
    "\n",
    "def get_case(term, docket):\n",
    "    \"\"\"Get the info of the case and fetch all\n",
    "    transcripts that the info links to\"\"\"\n",
    "    url = f\"https://api.oyez.org/cases/{term}/{docket}\"\n",
    "    docket_data = get_http_json(url)\n",
    "\n",
    "    if not (\n",
    "        \"oral_argument_audio\" in docket_data and docket_data[\"oral_argument_audio\"]\n",
    "    ):\n",
    "        # no oral arguments for this case yet\n",
    "        # fail so we will try again later\n",
    "        print(f\"No oral arguments for docket {docket}\")\n",
    "        return (docket_data, [])\n",
    "\n",
    "    oral_argument_audio = docket_data[\"oral_argument_audio\"]\n",
    "    transcripts = []\n",
    "    for link in oral_argument_audio:\n",
    "        t = get_http_json(link[\"href\"])\n",
    "        transcripts.append(t)\n",
    "\n",
    "    return docket_data, transcripts\n",
    "\n",
    "\n",
    "def getAudio(transcripts):\n",
    "    num_files = len(transcripts)\n",
    "    audio_list = []\n",
    "    for t in transcripts:\n",
    "        media_dicts = t[\"media_file\"]\n",
    "        if media_dicts[0] is not None:  # handle weird cases\n",
    "            # just incase theres more than one, there shouldnt be but they re in a weird list\n",
    "            for media_dict in media_dicts:\n",
    "                audio_list.append(media_dict[\"href\"])\n",
    "    return [num_files, audio_list]\n",
    "\n",
    "\n",
    "# gets transcript along with metadata\n",
    "def getTranscript(transcripts):\n",
    "    transcript_list = []\n",
    "    speaker_list = []\n",
    "    speaker_type_list = []\n",
    "    time_list = []\n",
    "\n",
    "    # parse through many levels of json file\n",
    "    for t in transcripts:\n",
    "        sections = t[\"transcript\"][\"sections\"]\n",
    "        for section in sections:\n",
    "            turns = section[\"turns\"]\n",
    "\n",
    "            for turn in turns:\n",
    "\n",
    "                # collect speaker\n",
    "                try:\n",
    "                    speaker = turn[\"speaker\"][\"name\"]\n",
    "                except:\n",
    "                    speaker = \"<UNK>\"\n",
    "                speaker_list.append(speaker)\n",
    "\n",
    "                # collect speaker type\n",
    "                try:\n",
    "                    roles = turn[\"speaker\"][\"roles\"]\n",
    "\n",
    "                    if isinstance(turn[\"speaker\"][\"roles\"], list):\n",
    "                        roles = turn[\"speaker\"][\"roles\"]\n",
    "                        multiple_roles = []\n",
    "                        for role in roles:\n",
    "                            multiple_roles.append(role[\"type\"])\n",
    "                        speaker_type_list.append(multiple_roles)\n",
    "\n",
    "                    else:\n",
    "                        speaker_type_list.append(\n",
    "                            [\"Other\"]\n",
    "                        )  # Other is most likely Lawyer\n",
    "                except:\n",
    "                    speaker_type_list.append([\"Other\"])\n",
    "\n",
    "                # collect text and time\n",
    "                texts = turn[\"text_blocks\"]\n",
    "                texts_out = []\n",
    "                times_out = []\n",
    "                for text in texts:\n",
    "                    texts_out.append(text[\"text\"])\n",
    "                    times_out.append((text[\"start\"], text[\"stop\"]))\n",
    "\n",
    "                transcript_list.append(texts_out)\n",
    "                time_list.append(times_out)\n",
    "\n",
    "    return transcript_list, speaker_list, speaker_type_list, time_list\n",
    "\n",
    "\n",
    "def getMeta(docket, data):\n",
    "\n",
    "    # get meta data as well as rearrange to desirable formal\n",
    "    transcript, speakers, speaker_roles, times = data[docket]\n",
    "\n",
    "    # Flatten times list\n",
    "    times_new = []\n",
    "    for t in times:\n",
    "        flatten = [item for sublist in t for item in sublist]\n",
    "        times_new.append(flatten)\n",
    "    # Last element of list is a 0 - cleanup\n",
    "    del times_new[-1][-1]\n",
    "\n",
    "    # Flatten speaker_roles list and replace nulls with \"Other\"\n",
    "    speaker_roles_clean = []\n",
    "    for i in speaker_roles:\n",
    "        if not i:\n",
    "            speaker_roles_clean.append(\"Other\")\n",
    "        else:\n",
    "            speaker_roles_clean.append(i[0])\n",
    "\n",
    "    # Remove all non-word characters in speakers' names\n",
    "    speakers = [re.sub(r\"[^\\w\\s]\", \"\", s) for s in speakers]\n",
    "    # Replace all runs of whitespace with underscorei in speakers' names\n",
    "    speakers = [re.sub(r\"\\s+\", \"_\", s) for s in speakers]\n",
    "\n",
    "    return transcript, speakers, speaker_roles_clean, times_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Query List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all case information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case_summaries can be retrieved through this API call: https://api.oyez.org/cases?per_page=0\n",
    "# case_summaries = requests.get(\"https://api.oyez.org/cases?per_page=0\")\n",
    "# case_summaries = pd.DataFrame(case_summaries.json())\n",
    "\n",
    "case_summaries = pd.read_json(\"../outputs/case_summaries.json\")\n",
    "case_summaries = case_summaries[[\"term\", \"docket_number\"]]\n",
    "\n",
    "case_summaries_filtered = case_summaries[\n",
    "    (case_summaries[\"term\"] >= years[0]) & (case_summaries[\"term\"] <= years[1])\n",
    "]\n",
    "\n",
    "if n_limit:\n",
    "    case_summaries_filtered = case_summaries_filtered.head(n=n_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_summaries_filtered.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get audio download links for filtered cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "\n",
    "for term, docket_number in case_summaries_filtered.itertuples(index=False):\n",
    "    docket_data, transcripts = get_case(term, docket_number)\n",
    "    data[docket_number] = transcripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get audio data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_data = {}\n",
    "\n",
    "missing_transcripts = []\n",
    "missing_audio = []\n",
    "for docket, transcript in data.items():\n",
    "    if bool(data[docket]) and type(data[docket][0][\"transcript\"]) == dict:\n",
    "        if getAudio(data[docket])[0] == 1:\n",
    "            temp = getAudio(data[docket])[1]\n",
    "            if len(temp) > 0:\n",
    "                # Found empty result, error-proofing\n",
    "                audio_data[docket] = temp[0]  # s3 link\n",
    "            else:\n",
    "                missing_audio.append(docket)\n",
    "        else:\n",
    "            missing_audio.append(docket)\n",
    "    else:\n",
    "        missing_transcripts.append(docket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dockets with no transcript information: 0\n",
      "Docket with no audio files: 0\n",
      "Collected Audio Data Links: 5\n"
     ]
    }
   ],
   "source": [
    "print(\"Dockets with no transcript information:\", len(missing_transcripts))\n",
    "print(\"Docket with no audio files:\", len(missing_audio))\n",
    "print(\"Collected Audio Data Links:\", len(audio_data.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting to CURL commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "curl_script = open(\"../scripts/mp3_curl_cmds.sh\", \"w\")\n",
    "\n",
    "if cluster_shell_start:\n",
    "    curl_script.writelines(cluster_shell_start)\n",
    "\n",
    "for docket, s3_link in audio_data.items():\n",
    "    curl_script.write(f\"curl -L {s3_link} -o {mp3_output_dir}{docket}.mp3 \\n\")\n",
    "\n",
    "curl_script.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run as `bash` script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# remove `capture` magic to see output\n",
    "!bash ../scripts/mp3_curl_cmds.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp3_meta_data = {}\n",
    "\n",
    "#  1. All have transcripts\n",
    "#  2. All have just 1 mp3 file\n",
    "for docket in audio_data.keys():\n",
    "    transcript_list, speaker_list, speaker_type_list, time_list = getTranscript(\n",
    "        data[docket]\n",
    "    )\n",
    "    mp3_meta_data[docket] = transcript_list, speaker_list, speaker_type_list, time_list\n",
    "\n",
    "with open(\"../outputs/oyez_metadata.json\", \"w+\") as f:\n",
    "    # use json.dump(mp3_meta_data, f, indent=4) to \"pretty-print\" with four spaces per indent\n",
    "    json.dump(mp3_meta_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to WAVs\n",
    "Bash Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "# If windows, run the following before: `dos2unix ../outputs/mp3_to_wav_win.sh`\n",
    "# A little buggy. Might need to reset it. Requires `ffmpeg` installed on system.\n",
    "!bash ../scripts/mp3_to_wav.sh ../outputs/mp3s/ ../outputs/wavs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../outputs/oyez_metadata.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "saved_dockets = []\n",
    "for file in os.listdir(\"../outputs/wavs/\"):\n",
    "    if file.endswith(\".wav\"):\n",
    "        saved_dockets.append(file.split(\".\")[0])\n",
    "\n",
    "infos = []\n",
    "# # Create transcript for wav files saved if certain criteria check out\n",
    "for docket in saved_dockets:\n",
    "    transcript, speakers, speaker_roles, times_new = getMeta(docket, data)\n",
    "    if len(transcript) == len(speakers) == len(speaker_roles) == len(times_new):\n",
    "        case_info = pd.DataFrame(\n",
    "            data={\n",
    "                \"times\": times_new,\n",
    "                \"speaker\": speakers,\n",
    "                \"speaker_role\": speaker_roles,\n",
    "                \"text\": transcript,\n",
    "            }\n",
    "        )\n",
    "        case_info[\"file\"] = docket\n",
    "        case_info[\"line\"] = case_info.index\n",
    "        case_info[\"start\"] = case_info[\"times\"].apply(lambda x: x[0])\n",
    "        case_info[\"end\"] = case_info[\"times\"].apply(lambda x: x[-1])\n",
    "        case_info[\"duration\"] = case_info[\"end\"] - case_info[\"start\"]\n",
    "        case_info[\"duration\"] = case_info[\"duration\"].apply(lambda x: round(x, 3))\n",
    "        case_info[\"text\"] = case_info[\"text\"].apply(lambda x: \" \".join(x))\n",
    "        case_info[\"word_count\"] = case_info[\"text\"].apply(lambda x: len(x.split(\" \")))\n",
    "\n",
    "        case_info = case_info[\n",
    "            [\n",
    "                \"file\",\n",
    "                \"line\",\n",
    "                \"start\",\n",
    "                \"end\",\n",
    "                \"speaker\",\n",
    "                \"speaker_role\",\n",
    "                \"word_count\",\n",
    "                \"duration\",\n",
    "                \"text\",\n",
    "            ]\n",
    "        ]\n",
    "        infos.append(case_info)\n",
    "\n",
    "all_info = pd.concat(infos)\n",
    "all_info = all_info.loc[all_info[\"speaker_role\"] == \"scotus_justice\"].reset_index(\n",
    "    drop=True\n",
    ")\n",
    "\n",
    "all_info['year'] = all_info[\"file\"].apply(lambda x: x.split(\"-\")[0])\n",
    "\n",
    "all_info.to_csv(\"../outputs/all_transcripts.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>line</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speaker_role</th>\n",
       "      <th>word_count</th>\n",
       "      <th>duration</th>\n",
       "      <th>text</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>12-1036</td>\n",
       "      <td>128</td>\n",
       "      <td>2172.987</td>\n",
       "      <td>2173.456</td>\n",
       "      <td>Elena_Kagan</td>\n",
       "      <td>scotus_justice</td>\n",
       "      <td>2</td>\n",
       "      <td>0.469</td>\n",
       "      <td>--consolidation case--</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>12-1036</td>\n",
       "      <td>34</td>\n",
       "      <td>825.443</td>\n",
       "      <td>827.177</td>\n",
       "      <td>John_G_Roberts_Jr</td>\n",
       "      <td>scotus_justice</td>\n",
       "      <td>6</td>\n",
       "      <td>1.734</td>\n",
       "      <td>Well, I know but I'm trying--</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12-1036</td>\n",
       "      <td>24</td>\n",
       "      <td>508.195</td>\n",
       "      <td>523.704</td>\n",
       "      <td>John_G_Roberts_Jr</td>\n",
       "      <td>scotus_justice</td>\n",
       "      <td>46</td>\n",
       "      <td>15.509</td>\n",
       "      <td>What if you have an executor and he's administ...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>12-682</td>\n",
       "      <td>75</td>\n",
       "      <td>1713.700</td>\n",
       "      <td>1723.223</td>\n",
       "      <td>John_G_Roberts_Jr</td>\n",
       "      <td>scotus_justice</td>\n",
       "      <td>32</td>\n",
       "      <td>9.523</td>\n",
       "      <td>And they did, and then after several years the...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        file  line     start       end            speaker    speaker_role  \\\n",
       "64   12-1036   128  2172.987  2173.456        Elena_Kagan  scotus_justice   \n",
       "17   12-1036    34   825.443   827.177  John_G_Roberts_Jr  scotus_justice   \n",
       "12   12-1036    24   508.195   523.704  John_G_Roberts_Jr  scotus_justice   \n",
       "499   12-682    75  1713.700  1723.223  John_G_Roberts_Jr  scotus_justice   \n",
       "\n",
       "     word_count  duration                                               text  \\\n",
       "64            2     0.469                             --consolidation case--   \n",
       "17            6     1.734                      Well, I know but I'm trying--   \n",
       "12           46    15.509  What if you have an executor and he's administ...   \n",
       "499          32     9.523  And they did, and then after several years the...   \n",
       "\n",
       "    year  \n",
       "64    12  \n",
       "17    12  \n",
       "12    12  \n",
       "499   12  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_info.sample(n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4909a92efbe4e002b0c7ca077249a8704a44839a693cc8fcae0e30e4ed0fc8bf"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
