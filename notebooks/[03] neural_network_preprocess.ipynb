{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "470c6236",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02a5ea03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "from pathlib import Path\n",
    "import math\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "\n",
    "from IPython.display import Audio, clear_output, display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f32fcaf",
   "metadata": {},
   "source": [
    "## Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c9d2256",
   "metadata": {},
   "outputs": [],
   "source": [
    "wavs_dir = \"../wavs2/\"\n",
    "wavs = [path for path in Path(wavs_dir).rglob(\"*.wav\")]\n",
    "\n",
    "output_dir = \"../outputs/npy2/\"\n",
    "transcript_path = \"../outputs/data_transcripts_v2.csv\"\n",
    "transcripts = pd.read_csv(transcript_path)\n",
    "\n",
    "target_sr = 16000\n",
    "target_channel = 1  # 1 or 2\n",
    "pitch_range = (\"C2\", \"C5\")\n",
    "\n",
    "# Re-process the start and end index as the files will be resampled\n",
    "transcripts[\"start_idx\"] = np.floor(transcripts[\"start\"] * target_sr).astype(int)\n",
    "transcripts[\"end_idx\"] = np.ceil(transcripts[\"end\"] * target_sr).astype(int)\n",
    "\n",
    "if not osp.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260056d9",
   "metadata": {},
   "source": [
    "## User Defined Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "085c06b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample(audio, current_sr, target_sr):\n",
    "    if current_sr == target_sr:\n",
    "        return audio\n",
    "    else:\n",
    "        new_audio = librosa.resample(audio, current_sr, target_sr)\n",
    "        return new_audio\n",
    "\n",
    "\n",
    "def rechannel(audio, target_channel):\n",
    "    current_shape = audio.shape\n",
    "    if target_channel == 1:\n",
    "        if len(current_shape) == 1:\n",
    "            return audio\n",
    "        else:\n",
    "            new_audio = librosa.to_mono(audio)\n",
    "            return new_audio\n",
    "    else:\n",
    "        if len(current_shape) == 2:\n",
    "            return audio\n",
    "        else:\n",
    "            new_audio = np.column_stack([audio, audio])\n",
    "            return new_audio\n",
    "\n",
    "\n",
    "def extract_pitch(audio, pitch_range=(\"C2\", \"C5\"), impute_val=0.0, log=True):\n",
    "    f0, voiced_flags, voiced_probs = librosa.pyin(\n",
    "        y=audio,\n",
    "        fmin=librosa.note_to_hz(pitch_range[0]),\n",
    "        fmax=librosa.note_to_hz(pitch_range[1]),\n",
    "    )\n",
    "    if log:\n",
    "        f0 = np.log2(f0)\n",
    "    f0_inputed = np.nan_to_num(f0, nan=impute_val)\n",
    "    return (f0_inputed, voiced_flags, voiced_probs)\n",
    "\n",
    "\n",
    "def extract_onset(audio, sampling_rate, max_size=5):\n",
    "    onset_strengths = librosa.onset.onset_strength(\n",
    "        y=audio, sr=sampling_rate, max_size=max_size\n",
    "    )\n",
    "    onset_frames = librosa.onset.onset_detect(y=audio, sr=sampling_rate, units=\"frames\")\n",
    "    onset_flags = np.zeros(onset_strengths.shape[0])\n",
    "    onset_flags[onset_frames] = 1\n",
    "    return (onset_strengths, onset_flags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bc0391",
   "metadata": {},
   "source": [
    "## Extract Features (One File Sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4448cd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Path\n",
    "file_path = wavs[0]\n",
    "\n",
    "# Load in audio\n",
    "audio_array, audio_sr = librosa.load(\n",
    "    file_path, sr=librosa.core.get_samplerate(file_path)\n",
    ")\n",
    "\n",
    "# Pre-process (resample, rechannel)\n",
    "audio_array = resample(audio_array, audio_sr, target_sr)\n",
    "audio_array = rechannel(audio_array, target_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "42834f79",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item: 36  |  Line: 142  |  Progress: 97%\n",
      "Elapsed Time: 79.36s\n",
      "Total Time: 82.48s\n"
     ]
    }
   ],
   "source": [
    "file_transcripts = transcripts.loc[transcripts[\"file\"] == file_path.name]\n",
    "\n",
    "print(file_path.name)\n",
    "print(f\"{len(file_transcripts)} transcript lines\")\n",
    "\n",
    "# Iterate over transcript metadata\n",
    "# Segment clip by start and end indices\n",
    "\n",
    "shapes = []\n",
    "st = time()\n",
    "for x in file_transcripts.iterrows():\n",
    "    row = x[1]\n",
    "    clear_output(wait=True)\n",
    "    print(\n",
    "        \"Item:\",\n",
    "        x[0],\n",
    "        \" |  Line:\",\n",
    "        row[\"line\"],\n",
    "        \" |  Progress:\",\n",
    "        f\"{round(100*(x[0]/file_transcripts.shape[0]))}%\",\n",
    "    )\n",
    "    print(f\"Elapsed Time: {round(time() - st, 2)}s\")\n",
    "\n",
    "    segment = audio_array[row[\"start_idx\"] : row[\"end_idx\"]]\n",
    "    f0_inputed, voiced_flags, voiced_probs = extract_pitch(\n",
    "        segment, target_sr, pitch_range, log=True\n",
    "    )\n",
    "    onset_strengths, onset_flags = extract_onset(segment, target_sr)\n",
    "    full_array = np.column_stack(\n",
    "        (f0_inputed, voiced_flags, voiced_probs, onset_strengths, onset_flags)\n",
    "    )\n",
    "    np.save(osp.join(output_dir, f\"{file_path.name}_{row['line']}.npy\"), full_array)\n",
    "\n",
    "    shapes.append(full_array.shape)\n",
    "\n",
    "# For record keeping, used to decide max_lens\n",
    "np.save(\n",
    "    osp.join(output_dir, f\"{file_path.name}_shapes.npy\"),\n",
    "    np.array([s[0] for s in shapes]),\n",
    ")\n",
    "print(f\"Total Time: {round(time() - st, 2)}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bdb1ff",
   "metadata": {},
   "source": [
    "## All Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e3be1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11-681.wav\n",
      "Item: 0  |  Line: 4  |  Progress: 0%\n",
      "Elapsed Time: 0.0s\n",
      "Total Time: 1.09s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yagne\\anaconda3\\envs\\grandstanding\\lib\\site-packages\\librosa\\filters.py:238: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "files_list = list(transcripts[\"file\"].unique())\n",
    "length = len(files_list)\n",
    "chunks = 8\n",
    "\n",
    "split_size = math.ceil(length / chunks)\n",
    "\n",
    "[\n",
    "    files_list[max(0, i * split_size) : min(length, (i + 1) * split_size)]\n",
    "    for i in range(chunks)\n",
    "]\n",
    "\n",
    "\n",
    "for i, w in enumerate(wavs):\n",
    "    # Load in audio\n",
    "    audio_array, audio_sr = librosa.load(w, sr=librosa.core.get_samplerate(w))\n",
    "\n",
    "    # Pre-process (resample, rechannel)\n",
    "    audio_array = resample(audio_array, audio_sr, target_sr)\n",
    "    audio_array = rechannel(audio_array, target_channel)\n",
    "\n",
    "    file_transcripts = transcripts.loc[\n",
    "        transcripts[\"file\"] == w.name.replace(\".wav\", \"\")\n",
    "    ].reset_index(drop=True)\n",
    "\n",
    "    print(w.name)\n",
    "    print(f\"{len(file_transcripts)} transcript lines\")\n",
    "\n",
    "    # Iterate over transcript metadata\n",
    "    # Segment clip by start and end indices\n",
    "\n",
    "    shapes = []\n",
    "    st = time()\n",
    "    for x in file_transcripts.iterrows():\n",
    "        row = x[1]\n",
    "        clear_output(wait=True)\n",
    "        print(w.name)\n",
    "        print(\n",
    "            \"Item:\",\n",
    "            x[0],\n",
    "            \" |  Line:\",\n",
    "            row[\"line\"],\n",
    "            \" |  Progress:\",\n",
    "            f\"{round(100*(x[0]/file_transcripts.shape[0]))}%\",\n",
    "        )\n",
    "        print(f\"Elapsed Time: {round(time() - st, 2)}s\")\n",
    "\n",
    "        try:\n",
    "\n",
    "            segment = audio_array[row[\"start_idx\"] : row[\"end_idx\"]]\n",
    "            f0_inputed, voiced_flags, voiced_probs = extract_pitch(\n",
    "                segment, pitch_range, log=True\n",
    "            )\n",
    "            onset_strengths, onset_flags = extract_onset(segment, target_sr)\n",
    "            full_array = np.column_stack(\n",
    "                (f0_inputed, voiced_flags, voiced_probs, onset_strengths, onset_flags)\n",
    "            )\n",
    "            np.save(\n",
    "                osp.join(output_dir, f\"{row['file']}_{row['line']}.npy\"), full_array\n",
    "            )\n",
    "\n",
    "            shapes.append(full_array.shape)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # For record keeping, used to decide max_lens\n",
    "    np.save(\n",
    "        osp.join(output_dir, f\"{w.name.replace('.wav','')}_shapes.npy\"),\n",
    "        np.array([s[0] for s in shapes]),\n",
    "    )\n",
    "\n",
    "print(f\"Total Time: {round(time() - st, 2)}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02fa2bb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\n",
    "    [\n",
    "        files_list[max(0, i * split_size) : min(length, (i + 1) * split_size)]\n",
    "        for i in range(chunks)\n",
    "    ][2]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
