{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "470c6236",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02a5ea03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "\n",
    "from IPython.display import Audio, clear_output, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dc53a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f32fcaf",
   "metadata": {},
   "source": [
    "## Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c9d2256",
   "metadata": {},
   "outputs": [],
   "source": [
    "wavs_dir = \"../wavs/\"\n",
    "wavs = [path for path in Path(wavs_dir).rglob(\"*.wav\")]\n",
    "\n",
    "output_dir = \"../outputs/npy2/\"\n",
    "transcript_path = \"../outputs/all_transcripts.csv\"\n",
    "transcripts = pd.read_csv(transcript_path)\n",
    "\n",
    "target_sr = 16000\n",
    "target_channel = 1  # 1 or 2\n",
    "pitch_range = (\"C2\", \"C5\")\n",
    "\n",
    "# Re-process the start and end index as the files will be resampled\n",
    "transcripts[\"start_idx\"] = np.floor(transcripts[\"start\"] * target_sr).astype(int)\n",
    "transcripts[\"end_idx\"] = np.ceil(transcripts[\"end\"] * target_sr).astype(int)\n",
    "\n",
    "if not osp.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260056d9",
   "metadata": {},
   "source": [
    "## User Defined Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "085c06b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample(audio, current_sr, target_sr):\n",
    "    if current_sr == target_sr:\n",
    "        return audio\n",
    "    else:\n",
    "        new_audio = librosa.resample(audio, current_sr, target_sr)\n",
    "        return new_audio\n",
    "\n",
    "\n",
    "def rechannel(audio, target_channel):\n",
    "    current_shape = audio.shape\n",
    "    if target_channel == 1:\n",
    "        if len(current_shape) == 1:\n",
    "            return audio\n",
    "        else:\n",
    "            new_audio = librosa.to_mono(audio)\n",
    "            return new_audio\n",
    "    else:\n",
    "        if len(current_shape) == 2:\n",
    "            return audio\n",
    "        else:\n",
    "            new_audio = np.column_stack([audio, audio])\n",
    "            return new_audio\n",
    "\n",
    "\n",
    "def extract_pitch(\n",
    "    audio, pitch_range=(\"C2\", \"C5\"), impute_val=0.0, log=True\n",
    "):\n",
    "    f0, voiced_flags, voiced_probs = librosa.pyin(\n",
    "        y=audio,\n",
    "        fmin=librosa.note_to_hz(pitch_range[0]),\n",
    "        fmax=librosa.note_to_hz(pitch_range[1]),\n",
    "    )\n",
    "    if log:\n",
    "        f0 = np.log2(f0)\n",
    "    f0_inputed = np.nan_to_num(f0, nan=impute_val)\n",
    "    return (f0_inputed, voiced_flags, voiced_probs)\n",
    "\n",
    "\n",
    "def extract_onset(audio, sampling_rate, max_size=5):\n",
    "    onset_strengths = librosa.onset.onset_strength(y=audio, sr=sampling_rate, max_size=max_size)\n",
    "    onset_frames = librosa.onset.onset_detect(y=audio, sr=sampling_rate, units=\"frames\")\n",
    "    onset_flags = np.zeros(onset_strengths.shape[0])\n",
    "    onset_flags[onset_frames] = 1\n",
    "    return (onset_strengths, onset_flags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bc0391",
   "metadata": {},
   "source": [
    "## Extract Features (One File Sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4448cd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Path\n",
    "file_path = wavs[0]\n",
    "\n",
    "# Load in audio\n",
    "audio_array, audio_sr = librosa.load(\n",
    "    file_path, sr=librosa.core.get_samplerate(file_path)\n",
    ")\n",
    "\n",
    "# Pre-process (resample, rechannel)\n",
    "audio_array = resample(audio_array, audio_sr, target_sr)\n",
    "audio_array = rechannel(audio_array, target_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42834f79",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item: 2  |  Line: 7  |  Progress: 5%\n",
      "Elapsed Time: 3.7s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24948/596129188.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0msegment\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maudio_array\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"start_idx\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"end_idx\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     f0_inputed, voiced_flags, voiced_probs = extract_pitch(\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0msegment\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpitch_range\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     )\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24948/3467665678.py\u001b[0m in \u001b[0;36mextract_pitch\u001b[1;34m(audio, pitch_range, impute_val, log)\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0maudio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpitch_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"C2\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"C5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimpute_val\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m ):\n\u001b[1;32m---> 28\u001b[1;33m     f0, voiced_flags, voiced_probs = librosa.pyin(\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maudio\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mfmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnote_to_hz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpitch_range\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\grandstanding\\lib\\site-packages\\librosa\\core\\pitch.py\u001b[0m in \u001b[0;36mpyin\u001b[1;34m(y, fmin, fmax, sr, frame_length, win_length, hop_length, n_thresholds, beta_parameters, boltzmann_parameter, resolution, max_transition_rate, switch_prob, no_trough_prob, fill_na, center, pad_mode)\u001b[0m\n\u001b[0;32m    862\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m     \u001b[1;31m# Viterbi decoding.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 864\u001b[1;33m     \u001b[0mstates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msequence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mviterbi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation_probs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransition\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp_init\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m     \u001b[1;31m# Find f0 corresponding to each decoded pitch bin.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "file_transcripts = transcripts.loc[transcripts[\"file\"] == file_path.name]\n",
    "\n",
    "print(file_path.name)\n",
    "print(f\"{len(file_transcripts)} transcript lines\")\n",
    "\n",
    "# Iterate over transcript metadata\n",
    "# Segment clip by start and end indices\n",
    "\n",
    "shapes = []\n",
    "st = time()\n",
    "for x in file_transcripts.iterrows():\n",
    "    row = x[1]\n",
    "    clear_output(wait=True)\n",
    "    print(\n",
    "        \"Item:\",\n",
    "        x[0],\n",
    "        \" |  Line:\",\n",
    "        row[\"line\"],\n",
    "        \" |  Progress:\",\n",
    "        f\"{round(100*(x[0]/file_transcripts.shape[0]))}%\",\n",
    "    )\n",
    "    print(f\"Elapsed Time: {round(time() - st, 2)}s\")\n",
    "\n",
    "    segment = audio_array[row[\"start_idx\"] : row[\"end_idx\"]]\n",
    "    f0_inputed, voiced_flags, voiced_probs = extract_pitch(\n",
    "        segment, pitch_range, log=True\n",
    "    )\n",
    "    onset_strengths, onset_flags = extract_onset(segment, target_sr)\n",
    "    full_array = np.column_stack(\n",
    "        (f0_inputed, voiced_flags, voiced_probs, onset_strengths, onset_flags)\n",
    "    )\n",
    "    np.save(osp.join(output_dir, f\"{file_path.name}_{row['line']}.npy\"), full_array)\n",
    "\n",
    "    shapes.append(full_array.shape)\n",
    "\n",
    "# For record keeping, used to decide max_lens\n",
    "np.save(\n",
    "    osp.join(output_dir, f\"{file_path.name}_shapes.npy\"),\n",
    "    np.array([s[0] for s in shapes]),\n",
    ")\n",
    "print(f\"Total Time: {round(time() - st, 2)}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bdb1ff",
   "metadata": {},
   "source": [
    "## Loop Over All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3979bd91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18-1447.wav\n",
      "41 transcript lines\n",
      "Item: 127  |  Line: 256  |  Progress: 310%\n",
      "Elapsed Time: 85.22s\n",
      "Total Time: 86.72s\n"
     ]
    }
   ],
   "source": [
    "for i,f in enumerate (wavs[1:3]):\n",
    "    # Load in audio\n",
    "    audio_array, audio_sr = librosa.load(\n",
    "        f, sr=librosa.core.get_samplerate(f)\n",
    "    )\n",
    "\n",
    "    # Pre-process (resample, rechannel)\n",
    "    audio_array = resample(audio_array, audio_sr, target_sr)\n",
    "    audio_array = rechannel(audio_array, target_channel)\n",
    "\n",
    "    file_transcripts = transcripts.loc[transcripts[\"file\"] == f.name]\n",
    "\n",
    "\n",
    "\n",
    "    # Iterate over transcript metadata\n",
    "    # Segment clip by start and end indices\n",
    "\n",
    "    shapes = []\n",
    "    st = time()\n",
    "    for j,x in enumerate(file_transcripts.iterrows()):\n",
    "        row = x[1]\n",
    "        clear_output(wait=True)\n",
    "        print(f.name)\n",
    "        print(f\"{len(file_transcripts)} transcript lines\")\n",
    "        print(\n",
    "            \"Item:\",\n",
    "            x[0],\n",
    "            \" |  Line:\",\n",
    "            row[\"line\"],\n",
    "            \" |  Progress:\",\n",
    "            f\"{round(100*(j/file_transcripts.shape[0]))}%\",\n",
    "        )\n",
    "        print(f\"Elapsed Time: {round(time() - st, 2)}s\")\n",
    "\n",
    "        segment = audio_array[row[\"start_idx\"] : row[\"end_idx\"]]\n",
    "        try:\n",
    "            f0_inputed, voiced_flags, voiced_probs = extract_pitch(\n",
    "                segment, pitch_range, log=True\n",
    "            )\n",
    "            onset_strengths, onset_flags = extract_onset(segment, target_sr)\n",
    "            full_array = np.column_stack(\n",
    "                (f0_inputed, voiced_flags, voiced_probs, onset_strengths, onset_flags)\n",
    "            )\n",
    "            np.save(osp.join(output_dir, f\"{row['file']}_{row['line']}.npy\"), full_array)\n",
    "        except:\n",
    "            pass\n",
    "            # Need to do something with the transcript that have bad segments\n",
    "        shapes.append(full_array.shape)\n",
    "\n",
    "    # For record keeping, used to decide max_lens\n",
    "    np.save(\n",
    "        osp.join(output_dir, f\"{f.name}_shapes.npy\"),\n",
    "        np.array([s[0] for s in shapes]),\n",
    "    )\n",
    "    print(f\"Total Time: {round(time() - st, 2)}s\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
