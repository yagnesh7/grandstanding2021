{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdd52252",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2FeatureExtractor, HubertModel, HubertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "import soundfile as sf\n",
    "\n",
    "\n",
    "from IPython.display import Audio, display, clear_output\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "072bc547",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../scripts/\")\n",
    "import data_loader as dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10cc9c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>line</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speaker_role</th>\n",
       "      <th>word_count</th>\n",
       "      <th>duration</th>\n",
       "      <th>text</th>\n",
       "      <th>start_idx</th>\n",
       "      <th>...</th>\n",
       "      <th>justice_year_onset_time_diff_mean_mean</th>\n",
       "      <th>justice_year_onset_time_diff_mean_std</th>\n",
       "      <th>justice_year_onset_time_diff_stddev_mean</th>\n",
       "      <th>justice_year_onset_time_diff_stddev_std</th>\n",
       "      <th>justice_year_onset_time_diff_entropy_mean</th>\n",
       "      <th>justice_year_onset_time_diff_entropy_std</th>\n",
       "      <th>justice_year_word_rate_mean</th>\n",
       "      <th>justice_year_word_rate_std</th>\n",
       "      <th>justice_year_onset_rate_mean</th>\n",
       "      <th>justice_year_onset_rate_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7626</th>\n",
       "      <td>15-8544</td>\n",
       "      <td>99</td>\n",
       "      <td>1761.06</td>\n",
       "      <td>1785.475</td>\n",
       "      <td>Samuel_A_Alito_Jr</td>\n",
       "      <td>scotus_justice</td>\n",
       "      <td>74</td>\n",
       "      <td>24.415</td>\n",
       "      <td>All right. So it's for vagueness purposes. Now...</td>\n",
       "      <td>28176960</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179352</td>\n",
       "      <td>0.028832</td>\n",
       "      <td>0.161813</td>\n",
       "      <td>0.033735</td>\n",
       "      <td>-122.598295</td>\n",
       "      <td>64.552798</td>\n",
       "      <td>2.866630</td>\n",
       "      <td>0.468534</td>\n",
       "      <td>7.023048</td>\n",
       "      <td>0.871192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15789</th>\n",
       "      <td>19-7</td>\n",
       "      <td>152</td>\n",
       "      <td>3195.68</td>\n",
       "      <td>3211.400</td>\n",
       "      <td>Brett_M_Kavanaugh</td>\n",
       "      <td>scotus_justice</td>\n",
       "      <td>50</td>\n",
       "      <td>15.720</td>\n",
       "      <td>On your -- on your definition of how we should...</td>\n",
       "      <td>51130880</td>\n",
       "      <td>...</td>\n",
       "      <td>0.236285</td>\n",
       "      <td>0.137546</td>\n",
       "      <td>0.222739</td>\n",
       "      <td>0.128992</td>\n",
       "      <td>-95.036539</td>\n",
       "      <td>66.024475</td>\n",
       "      <td>2.793239</td>\n",
       "      <td>0.448214</td>\n",
       "      <td>6.319411</td>\n",
       "      <td>1.750082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          file line    start       end            speaker    speaker_role  \\\n",
       "7626   15-8544   99  1761.06  1785.475  Samuel_A_Alito_Jr  scotus_justice   \n",
       "15789     19-7  152  3195.68  3211.400  Brett_M_Kavanaugh  scotus_justice   \n",
       "\n",
       "       word_count  duration  \\\n",
       "7626           74    24.415   \n",
       "15789          50    15.720   \n",
       "\n",
       "                                                    text  start_idx  ...  \\\n",
       "7626   All right. So it's for vagueness purposes. Now...   28176960  ...   \n",
       "15789  On your -- on your definition of how we should...   51130880  ...   \n",
       "\n",
       "       justice_year_onset_time_diff_mean_mean  \\\n",
       "7626                                 0.179352   \n",
       "15789                                0.236285   \n",
       "\n",
       "       justice_year_onset_time_diff_mean_std  \\\n",
       "7626                                0.028832   \n",
       "15789                               0.137546   \n",
       "\n",
       "       justice_year_onset_time_diff_stddev_mean  \\\n",
       "7626                                   0.161813   \n",
       "15789                                  0.222739   \n",
       "\n",
       "       justice_year_onset_time_diff_stddev_std  \\\n",
       "7626                                  0.033735   \n",
       "15789                                 0.128992   \n",
       "\n",
       "       justice_year_onset_time_diff_entropy_mean  \\\n",
       "7626                                 -122.598295   \n",
       "15789                                 -95.036539   \n",
       "\n",
       "       justice_year_onset_time_diff_entropy_std  justice_year_word_rate_mean  \\\n",
       "7626                                  64.552798                     2.866630   \n",
       "15789                                 66.024475                     2.793239   \n",
       "\n",
       "       justice_year_word_rate_std  justice_year_onset_rate_mean  \\\n",
       "7626                     0.468534                      7.023048   \n",
       "15789                    0.448214                      6.319411   \n",
       "\n",
       "       justice_year_onset_rate_std  \n",
       "7626                      0.871192  \n",
       "15789                     1.750082  \n",
       "\n",
       "[2 rows x 110 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_path =  \"C:/Users/yagne/Downloads/feature_extracts_11/\"\n",
    "data = pd.read_csv(\"../outputs/summary_data.csv\")\n",
    "data['line'] = data['line'].astype(str)\n",
    "data.sample(n=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac932eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Files: 3310\n"
     ]
    }
   ],
   "source": [
    "# mp3_clips = pickle.load(open(f\"C:/Users/yagne/Downloads/mp3_tensors.pkl\", \"rb\"))\n",
    "# mp3_clips = np.array([(m['file'], m['line']) for m in mp3_clips])\n",
    "\n",
    "from pathlib import Path\n",
    "pts = [path for path in Path(p_path).rglob(\"*.pt\")]\n",
    "print(\"PyTorch Files:\", len(pts))\n",
    "\n",
    "mp3_clip_names = [(\"-\".join(p[:-1]),p[-1]) for p in [p.name.replace(\".pt\", \"\").split('-') for p in pts]]\n",
    "\n",
    "clean_mp3_clips = []\n",
    "for m in mp3_clip_names:\n",
    "#     a = torch.load(f\"{p_path}{m[0]}-{m[1]}.pt\")\n",
    "#     if a.size()[0] != 1:\n",
    "#         print(m[0],m[1])\n",
    "#         print(a.size())\n",
    "#         b = a.mean(dim=0).unsqueeze(0)\n",
    "#         print(b.size())\n",
    "    a = data.loc[(data['file'] == m[0]) & (data['line'] == m[1])]\n",
    "    if a.shape[0] != 1:\n",
    "        continue\n",
    "#         print(m[0], m[1])\n",
    "    else:\n",
    "        clean_mp3_clips.append((m[0],m[1]))\n",
    "    \n",
    "mp3_clips = np.array(clean_mp3_clips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea6a1536",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HUBERTDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, mp3_clips, summary_data, pt_path):\n",
    "        self.mp3_clips = mp3_clips\n",
    "        self.summary_data = summary_data\n",
    "        self.pt_path = pt_path\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file, line = self.mp3_clips[idx]\n",
    "        input_values = torch.load(f\"{self.pt_path}{file}-{line}.pt\")\n",
    "        input_values.requires_grad = False\n",
    "      \n",
    "        if input_values.size()[0] != 1:\n",
    "            input_values = input_values.mean(dim=0)\n",
    "        else:\n",
    "            input_values = input_values.squeeze(0)\n",
    "        labels = self.summary_data.loc[\n",
    "            (self.summary_data['file'] == file) & (self.summary_data['line'] == line),'gs_score'\n",
    "        ].values[0]\n",
    "        labels = torch.tensor(labels).unsqueeze(0)\n",
    "        return {'input_values': input_values.float(),\n",
    "                'labels': labels.float()\n",
    "               }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mp3_clips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcd54397",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_values': tensor([[-0.0010, -0.0090, -0.1289,  ..., -0.2402,  0.1756, -0.3532],\n",
      "        [-0.1262, -0.0546, -0.1580,  ..., -0.2267,  0.2041, -0.1039],\n",
      "        [-0.1728, -0.0801, -0.1477,  ..., -0.2121,  0.2264,  0.1342],\n",
      "        ...,\n",
      "        [-0.1740,  0.0968, -0.0503,  ...,  0.1944, -0.3485, -0.2532],\n",
      "        [-0.1439,  0.1856,  0.0105,  ...,  0.0370, -0.2140,  0.0294],\n",
      "        [-0.0805,  0.2399,  0.0557,  ..., -0.0298, -0.0662,  0.1465]]), 'labels': tensor([-1.1868])}\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(HUBERTDataset(mp3_clips, data, p_path))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bab738e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HUBERTDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, mp3_clips, metadata, pt_path, batch_size=4, num_workers=4, seed=42):\n",
    "        super().__init__()\n",
    "        self.mp3_clips = mp3_clips\n",
    "        self.metadata = metadata\n",
    "        self.pt_path = pt_path\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.seed = seed\n",
    "        \n",
    "    def prepare_data(self):\n",
    "        rng = np.random.default_rng(self.seed)\n",
    "        indices = rng.permutation(self.mp3_clips.shape[0])\n",
    "        train_size = math.floor(len(indices) * 0.80)\n",
    "        val_size = math.floor(len(indices) * 0.10)   \n",
    "        self.train_idx = indices[:train_size]\n",
    "        self.val_idx = indices[train_size : train_size + val_size]\n",
    "        self.test_idx = indices[train_size + val_size :]\n",
    "        \n",
    "        print(train_size, val_size, len(indices) - train_size - val_size)\n",
    "        \n",
    "    def setup(self):\n",
    "        self.train_clips = self.mp3_clips[self.train_idx]\n",
    "        print(\"Train\",len(self.train_clips))\n",
    "        self.val_clips = self.mp3_clips[self.val_idx]\n",
    "        print(\"Val\",len(self.val_clips))\n",
    "        self.test_clips = self.mp3_clips[self.test_idx]\n",
    "        print(\"Test\",len(self.test_clips))\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        self.train_data = dl.HUBERTDataset(self.train_clips, self.metadata, self.pt_path)\n",
    "        train_loader = DataLoader(self.train_data, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers)\n",
    "        return train_loader\n",
    "    def val_dataloader(self):\n",
    "        self.val_data = dl.HUBERTDataset(self.val_clips, self.metadata, self.pt_path)\n",
    "        val_loader = DataLoader(self.val_data, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers)\n",
    "        return val_loader\n",
    "    def test_dataloader(self):\n",
    "        self.test_data = dl.HUBERTDataset(self.test_clips, self.metadata, self.pt_path)\n",
    "        test_loader = DataLoader(self.test_data, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers)\n",
    "        return test_loader\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a6edbcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HUBERTRegressor(pl.LightningModule):\n",
    "    def __init__(self, criterion, learning_rate=0.0001, hidden_size=768, projector_size=256):\n",
    "        super().__init__()\n",
    "        self.projector = nn.Linear(hidden_size, projector_size)\n",
    "        self.regressor = nn.Linear(projector_size, 1)\n",
    "        self.criterion = criterion\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "    def forward(self, x):\n",
    "        print(x.size())\n",
    "        projected = self.projector(x)\n",
    "        print(projected.size())\n",
    "        pooled_output = projected.mean(dim=1)\n",
    "        print(pooled_output.size())\n",
    "        pred = self.regressor(pooled_output)\n",
    "        print(pred.size())\n",
    "        return pred\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch['input_values'], batch['labels']\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch['input_values'], batch['labels']\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log('val_loss', loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch['input_values'], batch['labels']\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log('test_loss', loss, prog_bar=True, logger=True)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e186f7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yagne\\.conda\\envs\\grandstanding\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\callback_connector.py:147: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=<pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint object at 0x0000020D907E0BE0>)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=<pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint object at 0x0000020D907E0BE0>)`.\n",
      "  rank_zero_deprecation(\n",
      "C:\\Users\\yagne\\.conda\\envs\\grandstanding\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\callback_connector.py:90: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=1)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "C:\\Users\\yagne\\.conda\\envs\\grandstanding\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1579: UserWarning: GPU available but not used. Set the gpus flag in your trainer `Trainer(gpus=1)` or script `--gpus=1`.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath = \"checkpoints\",\n",
    "    filename = \"best-checkpoint\", \n",
    "    save_top_k=1, \n",
    "    verbose =True, \n",
    "    monitor = \"val_loss\",\n",
    "    mode=\"min\"\n",
    ")\n",
    "logger = TensorBoardLogger(\"hubert\")\n",
    "early_stopping_callback = EarlyStopping(monitor=\"val_loss\", patience = 2)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=20,\n",
    "    logger=logger,\n",
    "    gpus=0,\n",
    "    progress_bar_refresh_rate=1,\n",
    "    checkpoint_callback=checkpoint_callback,\n",
    "    callbacks = [early_stopping_callback],\n",
    "    overfit_batches=1,\n",
    "    log_every_n_steps=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "537a8fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HUBERTRegressor(criterion=nn.MSELoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b965d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2626 328 329\n",
      "Train 2626\n",
      "Val 328\n",
      "Test 329\n",
      "{'input_values': tensor([[[-1.3758e-01,  3.4996e-02,  3.3770e-01,  ...,  7.6871e-03,\n",
      "           1.2084e-01,  8.7262e-02],\n",
      "         [-1.4544e-01,  3.2742e-02,  3.3487e-01,  ...,  2.5508e-02,\n",
      "           1.0931e-01,  9.1300e-02],\n",
      "         [-1.5034e-01,  3.2271e-02,  3.3418e-01,  ...,  7.2643e-02,\n",
      "           8.0504e-02,  9.4673e-02],\n",
      "         ...,\n",
      "         [-2.6175e-01, -7.3572e-02, -3.2483e-01,  ...,  3.7043e-02,\n",
      "          -1.9819e-01, -5.9894e-02],\n",
      "         [-2.2815e-01,  3.0404e-03, -3.5803e-01,  ..., -2.1670e-04,\n",
      "          -1.6846e-01, -9.7121e-02],\n",
      "         [-1.8178e-01,  1.1292e-01,  2.7791e-01,  ..., -6.3717e-02,\n",
      "           3.5064e-02,  1.4509e-01]]]), 'labels': tensor([[0.1288]])}\n"
     ]
    }
   ],
   "source": [
    "dm = HUBERTDataModule(np.array(clean_mp3_clips), data, p_path, batch_size=1, num_workers=1)\n",
    "dm.prepare_data()\n",
    "dm.setup()\n",
    "\n",
    "b1 = next(iter(dm.val_dataloader()))\n",
    "print(b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b6cf016",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 12912), started 1:36:22 ago. (Use '!kill 12912' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-9d2abb2fbc91887\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-9d2abb2fbc91887\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./hubert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18c3a1be",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yagne\\.conda\\envs\\grandstanding\\lib\\site-packages\\pytorch_lightning\\core\\datamodule.py:469: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
      "  rank_zero_deprecation(\n",
      "\n",
      "  | Name      | Type    | Params\n",
      "--------------------------------------\n",
      "0 | projector | Linear  | 196 K \n",
      "1 | regressor | Linear  | 257   \n",
      "2 | criterion | MSELoss | 0     \n",
      "--------------------------------------\n",
      "197 K     Trainable params\n",
      "0         Non-trainable params\n",
      "197 K     Total params\n",
      "0.788     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yagne\\.conda\\envs\\grandstanding\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:110: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "C:\\Users\\yagne\\.conda\\envs\\grandstanding\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:110: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11bfcca963ce400d9217f168648f9ae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yagne\\.conda\\envs\\grandstanding\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:110: UserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc61795d629844f69b871c892f7f0d10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_loss': 0.0005455315113067627}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.0005455315113067627}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(model, dm)\n",
    "trainer.test(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e875484b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0379a01d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 999, 768])\n",
      "torch.Size([1, 999, 256])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0194]], grad_fn=<AddmmBackward0>), tensor([[0.1288]]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(b1['input_values']),b1['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc05e14f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
