{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "470c6236",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02a5ea03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "\n",
    "from IPython.display import Audio, clear_output, display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f32fcaf",
   "metadata": {},
   "source": [
    "## Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c9d2256",
   "metadata": {},
   "outputs": [],
   "source": [
    "wavs_dir = \"../outputs/wavs/\"\n",
    "wavs = [path for path in Path(wavs_dir).rglob(\"*.wav\")]\n",
    "\n",
    "output_dir = \"../outputs/npy/\"\n",
    "transcript_path = \"../outputs/all_transcripts.csv\"\n",
    "transcripts = pd.read_csv(transcript_path)\n",
    "\n",
    "target_sr = 16000\n",
    "target_channel = 1  # 1 or 2\n",
    "pitch_range = (\"C2\", \"C5\")\n",
    "\n",
    "# Re-process the start and end index as the files will be resampled\n",
    "transcripts[\"start_idx\"] = np.floor(transcripts[\"start\"] * target_sr).astype(int)\n",
    "transcripts[\"end_idx\"] = np.ceil(transcripts[\"end\"] * target_sr).astype(int)\n",
    "\n",
    "if not osp.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260056d9",
   "metadata": {},
   "source": [
    "## User Defined Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "085c06b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample(audio, current_sr, target_sr):\n",
    "    if current_sr == target_sr:\n",
    "        return audio\n",
    "    else:\n",
    "        new_audio = librosa.resample(audio, current_sr, target_sr)\n",
    "        return new_audio\n",
    "\n",
    "\n",
    "def rechannel(audio, target_channel):\n",
    "    current_shape = audio.shape\n",
    "    if target_channel == 1:\n",
    "        if len(current_shape) == 1:\n",
    "            return audio\n",
    "        else:\n",
    "            new_audio = librosa.to_mono(audio)\n",
    "            return new_audio\n",
    "    else:\n",
    "        if len(current_shape) == 2:\n",
    "            return audio\n",
    "        else:\n",
    "            new_audio = np.column_stack([audio, audio])\n",
    "            return new_audio\n",
    "\n",
    "\n",
    "def extract_pitch(audio, pitch_range=(\"C2\", \"C5\"), impute_val=0.0, log=True):\n",
    "    f0, voiced_flags, voiced_probs = librosa.pyin(\n",
    "        y=audio,\n",
    "        fmin=librosa.note_to_hz(pitch_range[0]),\n",
    "        fmax=librosa.note_to_hz(pitch_range[1]),\n",
    "    )\n",
    "    if log:\n",
    "        f0 = np.log2(f0)\n",
    "    f0_inputed = np.nan_to_num(f0, nan=impute_val)\n",
    "    return (f0_inputed, voiced_flags, voiced_probs)\n",
    "\n",
    "\n",
    "def extract_onset(audio, sampling_rate, max_size=5):\n",
    "    onset_strengths = librosa.onset.onset_strength(\n",
    "        y=audio, sr=sampling_rate, max_size=max_size\n",
    "    )\n",
    "    onset_frames = librosa.onset.onset_detect(y=audio, sr=sampling_rate, units=\"frames\")\n",
    "    onset_flags = np.zeros(onset_strengths.shape[0])\n",
    "    onset_flags[onset_frames] = 1\n",
    "    return (onset_strengths, onset_flags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d2dd88",
   "metadata": {},
   "source": [
    "# Extract Onset and Pitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e3be1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12-1036.wav\n",
      "Item: 97  |  Line: 193  |  Progress: 92%\n",
      "Elapsed Time: 277.28s\n"
     ]
    }
   ],
   "source": [
    "for i, w in enumerate(wavs):\n",
    "    # Load in audio\n",
    "    audio_array, audio_sr = librosa.load(w, sr=librosa.core.get_samplerate(w))\n",
    "\n",
    "    # Pre-process (resample, rechannel)\n",
    "    audio_array = resample(audio_array, audio_sr, target_sr)\n",
    "    audio_array = rechannel(audio_array, target_channel)\n",
    "\n",
    "    file_transcripts = transcripts.loc[\n",
    "        transcripts[\"file\"] == w.name.replace(\".wav\", \"\")\n",
    "    ].reset_index(drop=True)\n",
    "\n",
    "    print(w.name)\n",
    "    print(f\"{len(file_transcripts)} transcript lines\")\n",
    "\n",
    "    # Iterate over transcript metadata\n",
    "    # Segment clip by start and end indices\n",
    "\n",
    "    shapes = []\n",
    "    st = time()\n",
    "    for x in file_transcripts.iterrows():\n",
    "        row = x[1]\n",
    "        clear_output(wait=True)\n",
    "        print(w.name)\n",
    "        print(\n",
    "            \"Item:\",\n",
    "            x[0],\n",
    "            \" |  Line:\",\n",
    "            row[\"line\"],\n",
    "            \" |  Progress:\",\n",
    "            f\"{round(100*(x[0]/file_transcripts.shape[0]))}%\",\n",
    "        )\n",
    "        print(f\"Elapsed Time: {round(time() - st, 2)}s\")\n",
    "\n",
    "        try:\n",
    "            segment = audio_array[row[\"start_idx\"] : row[\"end_idx\"]]\n",
    "            f0_inputed, voiced_flags, voiced_probs = extract_pitch(\n",
    "                segment, pitch_range, log=True\n",
    "            )\n",
    "            onset_strengths, onset_flags = extract_onset(segment, target_sr)\n",
    "            full_array = np.column_stack(\n",
    "                (f0_inputed, voiced_flags, voiced_probs, onset_strengths, onset_flags)\n",
    "            )\n",
    "            np.save(\n",
    "                osp.join(output_dir, f\"{row['file']}_{row['line']}.npy\"), full_array\n",
    "            )\n",
    "\n",
    "            shapes.append(full_array.shape)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # For record keeping, used to decide max_lens\n",
    "    np.save(\n",
    "        osp.join(output_dir, f\"{w.name.replace('.wav','')}_shapes.npy\"),\n",
    "        np.array([s[0] for s in shapes]),\n",
    "    )\n",
    "\n",
    "print(f\"Total Time: {round(time() - st, 2)}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5afaf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
