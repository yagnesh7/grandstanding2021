{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddc42de3",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee98cc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "\n",
    "from IPython.display import Audio, clear_output, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "417530d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1bc9c5",
   "metadata": {},
   "source": [
    "## Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8809c361",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = \"bert-base-uncased\"\n",
    "pretrained_model = (\n",
    "    \"../models/bert_pretrained/\"  # Expects the pre-trained weights to exist\n",
    ")\n",
    "transcripts_path = \"../outputs/all_transcripts_v2.csv\"\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a895bd1c",
   "metadata": {},
   "source": [
    "## User-Defined Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea6b7f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GrandStand_Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels, info):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "        self.info = info\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        item[\"info\"] = self.info[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c39af86",
   "metadata": {},
   "source": [
    "## Load Transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07b4d807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>line</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speaker_role</th>\n",
       "      <th>word_count</th>\n",
       "      <th>duration</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>12-1036</td>\n",
       "      <td>191</td>\n",
       "      <td>3448.946</td>\n",
       "      <td>3453.195</td>\n",
       "      <td>Antonin_Scalia</td>\n",
       "      <td>scotus_justice</td>\n",
       "      <td>10</td>\n",
       "      <td>4.249</td>\n",
       "      <td>Did not the Fifth Circuit decide that State la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>12-1036</td>\n",
       "      <td>86</td>\n",
       "      <td>1683.706</td>\n",
       "      <td>1710.290</td>\n",
       "      <td>Sonia_Sotomayor</td>\n",
       "      <td>scotus_justice</td>\n",
       "      <td>59</td>\n",
       "      <td>26.584</td>\n",
       "      <td>So how do you remand a case when it involves u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>12-138</td>\n",
       "      <td>73</td>\n",
       "      <td>2003.816</td>\n",
       "      <td>2029.166</td>\n",
       "      <td>Elena_Kagan</td>\n",
       "      <td>scotus_justice</td>\n",
       "      <td>64</td>\n",
       "      <td>25.350</td>\n",
       "      <td>Because you read this through your brief, and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>12-515</td>\n",
       "      <td>296</td>\n",
       "      <td>3621.849</td>\n",
       "      <td>3646.082</td>\n",
       "      <td>Stephen_G_Breyer</td>\n",
       "      <td>scotus_justice</td>\n",
       "      <td>75</td>\n",
       "      <td>24.233</td>\n",
       "      <td>They didn't participate in the convention and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>12-138</td>\n",
       "      <td>4</td>\n",
       "      <td>72.212</td>\n",
       "      <td>126.164</td>\n",
       "      <td>Sonia_Sotomayor</td>\n",
       "      <td>scotus_justice</td>\n",
       "      <td>128</td>\n",
       "      <td>53.952</td>\n",
       "      <td>All right. So if the issue is what did the par...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        file  line     start       end           speaker    speaker_role  \\\n",
       "96   12-1036   191  3448.946  3453.195    Antonin_Scalia  scotus_justice   \n",
       "43   12-1036    86  1683.706  1710.290   Sonia_Sotomayor  scotus_justice   \n",
       "257   12-138    73  2003.816  2029.166       Elena_Kagan  scotus_justice   \n",
       "458   12-515   296  3621.849  3646.082  Stephen_G_Breyer  scotus_justice   \n",
       "222   12-138     4    72.212   126.164   Sonia_Sotomayor  scotus_justice   \n",
       "\n",
       "     word_count  duration                                               text  \n",
       "96           10     4.249  Did not the Fifth Circuit decide that State la...  \n",
       "43           59    26.584  So how do you remand a case when it involves u...  \n",
       "257          64    25.350  Because you read this through your brief, and ...  \n",
       "458          75    24.233  They didn't participate in the convention and ...  \n",
       "222         128    53.952  All right. So if the issue is what did the par...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcripts = pd.read_csv(transcripts_path)\n",
    "transcripts.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53197400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Cases: 5\n",
      "# Speech Segments: 565\n"
     ]
    }
   ],
   "source": [
    "print(\"# Cases:\", transcripts[\"file\"].nunique())\n",
    "print(\"# Speech Segments:\", transcripts.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38397b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = transcripts[\"text\"].tolist()\n",
    "metadata = transcripts.apply(lambda x: (x[\"file\"], x[\"line\"]), axis=1).tolist()\n",
    "fake_labels = [0 for i in range(transcripts.shape[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c352ab1",
   "metadata": {},
   "source": [
    "## Load BERT Pre-Trained Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "faf279a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(bert_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "08940ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41s\n"
     ]
    }
   ],
   "source": [
    "st = time()\n",
    "\n",
    "scotus_encoder = tokenizer(text, truncation=True, padding=True)\n",
    "scotus_dataset = GrandStand_Dataset(scotus_encoder, fake_labels, metadata)\n",
    "\n",
    "print(f\"{round(time() - st, 2)}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c9607002",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.86s\n"
     ]
    }
   ],
   "source": [
    "st = time()\n",
    "model = BertForSequenceClassification.from_pretrained(bert_model, num_labels=1)\n",
    "\n",
    "model.load_state_dict(torch.load(\"../models/bert_pretrained/BERTforGS\"))\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "print(f\"{round(time() - st, 2)}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd52621",
   "metadata": {},
   "source": [
    "## Generate Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca20283d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item 564\n",
      "Elapsed Time: 438.54s\n",
      "Total Time: 439.34s\n"
     ]
    }
   ],
   "source": [
    "st = time()\n",
    "\n",
    "inputs = []\n",
    "grandstanding_scores = []\n",
    "for i, batch in enumerate(scotus_dataset):\n",
    "    clear_output(wait=True)\n",
    "    print(\"Item\", i)\n",
    "    print(f\"Elapsed Time: {round(time() - st, 2)}s\")\n",
    "    with torch.no_grad():\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        file_info = batch[\"info\"]\n",
    "        outputs = model(\n",
    "            input_ids.reshape(1, -1), attention_mask=attention_mask.reshape(1, -1)\n",
    "        )\n",
    "        score = outputs.logits[0].item()\n",
    "        grandstanding_scores.append((file_info, score))\n",
    "\n",
    "print(f\"Total Time: {round(time() - st, 2)}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8b22cff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>line</th>\n",
       "      <th>gs_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>12-515</td>\n",
       "      <td>233</td>\n",
       "      <td>-1.352348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>12-515</td>\n",
       "      <td>25</td>\n",
       "      <td>0.152592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>12-1038</td>\n",
       "      <td>70</td>\n",
       "      <td>-0.233303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>12-138</td>\n",
       "      <td>121</td>\n",
       "      <td>-0.111669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>12-515</td>\n",
       "      <td>101</td>\n",
       "      <td>-0.778577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        file  line  gs_score\n",
       "425   12-515   233 -1.352348\n",
       "318   12-515    25  0.152592\n",
       "141  12-1038    70 -0.233303\n",
       "282   12-138   121 -0.111669\n",
       "357   12-515   101 -0.778577"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_df = pd.DataFrame(\n",
    "    data=[(i[0], i[1], s) for (i, s) in grandstanding_scores],\n",
    "    columns=[\"file\", \"line\", \"gs_score\"],\n",
    ")\n",
    "gs_df.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55495251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = gs_df[\"gs_score\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "57df9c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_df.to_csv(\"../outputs/bert_scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f33f08f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
